/home/nbrady/.conda/envs/vizdoom/lib/python3.11/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Using device: cuda
Environment created: VizdoomCorridor-v0
Observation space: Dict('gamevariables': Box(-3.4028235e+38, 3.4028235e+38, (1,), float32), 'screen': Box(0, 255, (240, 320, 3), uint8))
Action space: Discrete(8)
Using grid of 6x6 patches = 36 total patches
InfiniViT model initialized on: cuda
Models initialized on device
[Timestep 0] ViT encoder frozen.
---------------------------------
| Timestep                | 4096  |
| Episodes                | 33    |
| rollout/                |       |
|    ep_rew_mean (ext)    | -103.5963 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.0 |
|    time_elapsed         | 35    |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.176 |
|    clip_fraction        | 0.595 |
|    policy_loss          | 0.061 |
|    value_loss_ext       | 523.057 |
|    value_loss_int       | 28.712 |
|    entropy_loss         | 1.880 |
|    rnd_loss             | 0.051 |
|    need_loss            | 103.031 |
|    explained_variance   | -0.001 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 4096
*** New best model saved! Mean reward: -103.596 ***
[Timestep 4096] ViT encoder frozen.
---------------------------------
| Timestep                | 8192  |
| Episodes                | 63    |
| rollout/                |       |
|    ep_rew_mean (ext)    | -107.6452 |
|    best_mean_reward     | -103.596 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.2 |
|    time_elapsed         | 71    |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.040 |
|    clip_fraction        | 0.415 |
|    policy_loss          | 0.017 |
|    value_loss_ext       | 395.228 |
|    value_loss_int       | 34.247 |
|    entropy_loss         | 1.834 |
|    rnd_loss             | 0.001 |
|    need_loss            | 311.441 |
|    explained_variance   | 0.007 |
|    beta (learned)       | 0.728 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 8192] ViT encoder frozen.
---------------------------------
| Timestep                | 12288 |
| Episodes                | 83    |
| rollout/                |       |
|    ep_rew_mean (ext)    | -100.7380 |
|    best_mean_reward     | -103.596 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.3 |
|    time_elapsed         | 106   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.122 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 229.692 |
|    value_loss_int       | 45.315 |
|    entropy_loss         | 1.772 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.045 |
|    explained_variance   | -0.001 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 12288
*** New best model saved! Mean reward: -100.738 ***
[Timestep 12288] ViT encoder frozen.
---------------------------------
| Timestep                | 16384 |
| Episodes                | 109   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -104.4731 |
|    best_mean_reward     | -100.738 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.0 |
|    time_elapsed         | 142   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.013 |
|    clip_fraction        | 0.172 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 291.325 |
|    value_loss_int       | 26.878 |
|    entropy_loss         | 1.819 |
|    rnd_loss             | 0.000 |
|    need_loss            | 479.114 |
|    explained_variance   | 0.001 |
|    beta (learned)       | 0.727 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 16384] ViT encoder frozen.
---------------------------------
| Timestep                | 20480 |
| Episodes                | 139   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -100.1521 |
|    best_mean_reward     | -100.738 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.0 |
|    time_elapsed         | 177   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.094 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 310.308 |
|    value_loss_int       | 18.321 |
|    entropy_loss         | 1.861 |
|    rnd_loss             | 0.000 |
|    need_loss            | 7.230 |
|    explained_variance   | 0.001 |
|    beta (learned)       | 0.726 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 20480
*** New best model saved! Mean reward: -100.152 ***
[Timestep 20480] ViT encoder frozen.
---------------------------------
| Timestep                | 24576 |
| Episodes                | 165   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -104.8122 |
|    best_mean_reward     | -100.152 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.1 |
|    time_elapsed         | 213   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.015 |
|    clip_fraction        | 0.215 |
|    policy_loss          | 0.006 |
|    value_loss_ext       | 263.323 |
|    value_loss_int       | 13.768 |
|    entropy_loss         | 1.847 |
|    rnd_loss             | 0.000 |
|    need_loss            | 117.962 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.725 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 24576] ViT encoder frozen.
---------------------------------
| Timestep                | 28672 |
| Episodes                | 187   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -85.4775 |
|    best_mean_reward     | -100.152 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.3 |
|    time_elapsed         | 248   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.170 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 240.710 |
|    value_loss_int       | 23.762 |
|    entropy_loss         | 1.931 |
|    rnd_loss             | 0.000 |
|    need_loss            | 86.429 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.723 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 28672
*** New best model saved! Mean reward: -85.478 ***
[Timestep 28672] ViT encoder frozen.
---------------------------------
| Timestep                | 32768 |
| Episodes                | 212   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -99.6256 |
|    best_mean_reward     | -85.478 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 121.0 |
|    time_elapsed         | 283   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.106 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 238.693 |
|    value_loss_int       | 17.901 |
|    entropy_loss         | 1.907 |
|    rnd_loss             | 0.000 |
|    need_loss            | 64.032 |
|    explained_variance   | 0.001 |
|    beta (learned)       | 0.723 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 32768] ViT encoder frozen.
---------------------------------
| Timestep                | 36864 |
| Episodes                | 234   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -81.4540 |
|    best_mean_reward     | -85.478 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 121.3 |
|    time_elapsed         | 317   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.013 |
|    clip_fraction        | 0.129 |
|    policy_loss          | 0.003 |
|    value_loss_ext       | 226.484 |
|    value_loss_int       | 3.237 |
|    entropy_loss         | 1.896 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1.254 |
|    explained_variance   | -0.001 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 36864
*** New best model saved! Mean reward: -81.454 ***
[Timestep 36864] ViT encoder frozen.
---------------------------------
| Timestep                | 40960 |
| Episodes                | 255   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -84.7440 |
|    best_mean_reward     | -81.454 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 121.0 |
|    time_elapsed         | 352   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.012 |
|    clip_fraction        | 0.165 |
|    policy_loss          | 0.004 |
|    value_loss_ext       | 236.306 |
|    value_loss_int       | 0.527 |
|    entropy_loss         | 1.817 |
|    rnd_loss             | 0.000 |
|    need_loss            | 5.622 |
|    explained_variance   | 0.004 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 40960] ViT encoder frozen.
---------------------------------
| Timestep                | 45056 |
| Episodes                | 277   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -93.1471 |
|    best_mean_reward     | -81.454 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 121.5 |
|    time_elapsed         | 385   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.162 |
|    policy_loss          | 0.003 |
|    value_loss_ext       | 233.387 |
|    value_loss_int       | 3.352 |
|    entropy_loss         | 1.749 |
|    rnd_loss             | 0.000 |
|    need_loss            | 18.369 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 45056] ViT encoder frozen.
---------------------------------
| Timestep                | 49152 |
| Episodes                | 298   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -79.1344 |
|    best_mean_reward     | -81.454 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 121.4 |
|    time_elapsed         | 419   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.053 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 251.515 |
|    value_loss_int       | 17.654 |
|    entropy_loss         | 1.718 |
|    rnd_loss             | 0.000 |
|    need_loss            | 64.081 |
|    explained_variance   | 0.005 |
|    beta (learned)       | 0.719 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 49152
*** New best model saved! Mean reward: -79.134 ***
[Timestep 49152] ViT encoder frozen.
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts50000.pt at timestep 50000
---------------------------------
| Timestep                | 53248 |
| Episodes                | 321   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -58.7969 |
|    best_mean_reward     | -79.134 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.5 |
|    time_elapsed         | 455   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.081 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 259.521 |
|    value_loss_int       | 35.492 |
|    entropy_loss         | 1.696 |
|    rnd_loss             | 0.000 |
|    need_loss            | 45.361 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 53248
*** New best model saved! Mean reward: -58.797 ***
[Timestep 53248] ViT encoder frozen.
---------------------------------
| Timestep                | 57344 |
| Episodes                | 345   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -93.8806 |
|    best_mean_reward     | -58.797 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.9 |
|    time_elapsed         | 490   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 306.677 |
|    value_loss_int       | 817.544 |
|    entropy_loss         | 1.814 |
|    rnd_loss             | 0.000 |
|    need_loss            | 790.809 |
|    explained_variance   | 0.022 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 57344] ViT encoder frozen.
---------------------------------
| Timestep                | 61440 |
| Episodes                | 368   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -20.0299 |
|    best_mean_reward     | -58.797 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.8 |
|    time_elapsed         | 524   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.059 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 322.852 |
|    value_loss_int       | 221.883 |
|    entropy_loss         | 1.791 |
|    rnd_loss             | 0.000 |
|    need_loss            | 196.853 |
|    explained_variance   | 0.014 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 61440
*** New best model saved! Mean reward: -20.030 ***
[Timestep 61440] ViT encoder frozen.
---------------------------------
| Timestep                | 65536 |
| Episodes                | 393   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -31.0936 |
|    best_mean_reward     | -20.030 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.4 |
|    time_elapsed         | 559   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.085 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 383.520 |
|    value_loss_int       | 68.208 |
|    entropy_loss         | 1.729 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.363 |
|    explained_variance   | 0.019 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 65536] ViT encoder frozen.
---------------------------------
| Timestep                | 69632 |
| Episodes                | 417   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -11.0479 |
|    best_mean_reward     | -20.030 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 594   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.096 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 404.067 |
|    value_loss_int       | 334.339 |
|    entropy_loss         | 1.727 |
|    rnd_loss             | 0.000 |
|    need_loss            | 280.202 |
|    explained_variance   | 0.030 |
|    beta (learned)       | 0.712 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 69632
*** New best model saved! Mean reward: -11.048 ***
[Timestep 69632] ViT encoder frozen.
---------------------------------
| Timestep                | 73728 |
| Episodes                | 445   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -51.2832 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 632   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.047 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 488.853 |
|    value_loss_int       | 83.427 |
|    entropy_loss         | 1.714 |
|    rnd_loss             | 0.000 |
|    need_loss            | 121.199 |
|    explained_variance   | 0.031 |
|    beta (learned)       | 0.711 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 73728] ViT encoder frozen.
---------------------------------
| Timestep                | 77824 |
| Episodes                | 473   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -42.3303 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 667   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.103 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 487.223 |
|    value_loss_int       | 157.065 |
|    entropy_loss         | 1.701 |
|    rnd_loss             | 0.000 |
|    need_loss            | 129.853 |
|    explained_variance   | 0.018 |
|    beta (learned)       | 0.711 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 77824] ViT encoder frozen.
---------------------------------
| Timestep                | 81920 |
| Episodes                | 503   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -27.8731 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 702   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.070 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 584.404 |
|    value_loss_int       | 960.903 |
|    entropy_loss         | 1.556 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1009.587 |
|    explained_variance   | 0.036 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 81920] ViT encoder frozen.
---------------------------------
| Timestep                | 86016 |
| Episodes                | 535   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -37.5453 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 738   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.055 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 609.942 |
|    value_loss_int       | 278.036 |
|    entropy_loss         | 1.599 |
|    rnd_loss             | 0.000 |
|    need_loss            | 265.378 |
|    explained_variance   | 0.027 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 86016] ViT encoder frozen.
---------------------------------
| Timestep                | 90112 |
| Episodes                | 564   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -36.5201 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 773   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.100 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 716.755 |
|    value_loss_int       | 172.742 |
|    entropy_loss         | 1.623 |
|    rnd_loss             | 0.000 |
|    need_loss            | 153.427 |
|    explained_variance   | 0.033 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 90112] ViT encoder frozen.
---------------------------------
| Timestep                | 94208 |
| Episodes                | 588   |
| rollout/                |       |
|    ep_rew_mean (ext)    | 42.3306 |
|    best_mean_reward     | -11.048 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 808   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.112 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 516.076 |
|    value_loss_int       | 57.396 |
|    entropy_loss         | 1.645 |
|    rnd_loss             | 0.000 |
|    need_loss            | 37.677 |
|    explained_variance   | 0.031 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 94208
*** New best model saved! Mean reward: 42.331 ***
[Timestep 94208] ViT encoder frozen.
---------------------------------
| Timestep                | 98304 |
| Episodes                | 619   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -44.0833 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 845   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.069 |
|    policy_loss          | -0.004 |
|    value_loss_ext       | 625.210 |
|    value_loss_int       | 1013.605 |
|    entropy_loss         | 1.658 |
|    rnd_loss             | 0.000 |
|    need_loss            | 769.940 |
|    explained_variance   | 0.014 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
[Timestep 98304] ViT encoder frozen.
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts100000.pt at timestep 100000
---------------------------------
| Timestep                | 102400 |
| Episodes                | 652   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -7.8667 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 103.4 |
|    time_elapsed         | 885   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 645.806 |
|    value_loss_int       | 3074.961 |
|    entropy_loss         | 1.669 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1988.463 |
|    explained_variance   | 0.008 |
|    beta (learned)       | 0.716 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 106496 |
| Episodes                | 685   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -56.3388 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 921   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 565.993 |
|    value_loss_int       | 2709.925 |
|    entropy_loss         | 1.668 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1105.831 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 110592 |
| Episodes                | 720   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -59.0249 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 956   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.058 |
|    policy_loss          | -0.005 |
|    value_loss_ext       | 565.807 |
|    value_loss_int       | 1120.157 |
|    entropy_loss         | 1.603 |
|    rnd_loss             | 0.000 |
|    need_loss            | 249.816 |
|    explained_variance   | 0.001 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 114688 |
| Episodes                | 748   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -23.8053 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 991   |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 533.612 |
|    value_loss_int       | 1013.472 |
|    entropy_loss         | 1.604 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1364.538 |
|    explained_variance   | 0.016 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 118784 |
| Episodes                | 784   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -72.9838 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 1027  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.101 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 572.150 |
|    value_loss_int       | 0.005 |
|    entropy_loss         | 1.591 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.034 |
|    explained_variance   | -0.010 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 122880 |
| Episodes                | 817   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -55.7667 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 1062  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.013 |
|    clip_fraction        | 0.101 |
|    policy_loss          | 0.004 |
|    value_loss_ext       | 599.400 |
|    value_loss_int       | 0.005 |
|    entropy_loss         | 1.494 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.031 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.716 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 126976 |
| Episodes                | 846   |
| rollout/                |       |
|    ep_rew_mean (ext)    | 12.9978 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 1097  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.070 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 560.865 |
|    value_loss_int       | 0.004 |
|    entropy_loss         | 1.439 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.036 |
|    explained_variance   | 0.026 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 131072 |
| Episodes                | 879   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -25.1609 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1133  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.100 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 654.780 |
|    value_loss_int       | 0.005 |
|    entropy_loss         | 1.437 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.035 |
|    explained_variance   | 0.019 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 135168 |
| Episodes                | 914   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -75.3431 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1168  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.101 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 644.554 |
|    value_loss_int       | 0.005 |
|    entropy_loss         | 1.431 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.031 |
|    explained_variance   | 0.019 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 139264 |
| Episodes                | 949   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -88.9142 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 1203  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.039 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 659.136 |
|    value_loss_int       | 0.005 |
|    entropy_loss         | 1.418 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.024 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 143360 |
| Episodes                | 988   |
| rollout/                |       |
|    ep_rew_mean (ext)    | -75.7212 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 1239  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.041 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 536.037 |
|    value_loss_int       | 46.194 |
|    entropy_loss         | 1.455 |
|    rnd_loss             | 0.000 |
|    need_loss            | 44.183 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.724 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 147456 |
| Episodes                | 1020  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -26.0846 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 1274  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.104 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 507.032 |
|    value_loss_int       | 0.002 |
|    entropy_loss         | 1.458 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.041 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.721 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts150000.pt at timestep 150000
---------------------------------
| Timestep                | 151552 |
| Episodes                | 1050  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -35.5291 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 110.7 |
|    time_elapsed         | 1311  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.052 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 452.065 |
|    value_loss_int       | 0.002 |
|    entropy_loss         | 1.513 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.041 |
|    explained_variance   | 0.021 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 155648 |
| Episodes                | 1088  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -61.9337 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 1347  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.036 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 557.641 |
|    value_loss_int       | 0.004 |
|    entropy_loss         | 1.439 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.029 |
|    explained_variance   | -0.007 |
|    beta (learned)       | 0.721 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 159744 |
| Episodes                | 1128  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -103.8828 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 1382  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 458.490 |
|    value_loss_int       | 0.009 |
|    entropy_loss         | 1.347 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.016 |
|    explained_variance   | -0.029 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 163840 |
| Episodes                | 1170  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -82.2256 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1418  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.105 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 412.233 |
|    value_loss_int       | 0.015 |
|    entropy_loss         | 1.480 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.008 |
|    explained_variance   | -0.016 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 167936 |
| Episodes                | 1210  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -53.6738 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 1453  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.064 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 426.419 |
|    value_loss_int       | 0.020 |
|    entropy_loss         | 1.322 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.006 |
|    explained_variance   | -0.002 |
|    beta (learned)       | 0.721 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 172032 |
| Episodes                | 1248  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -47.7862 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 1488  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.112 |
|    policy_loss          | 0.002 |
|    value_loss_ext       | 437.935 |
|    value_loss_int       | 2.428 |
|    entropy_loss         | 1.421 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1.977 |
|    explained_variance   | 0.003 |
|    beta (learned)       | 0.719 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 176128 |
| Episodes                | 1280  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -41.7986 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 1524  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.056 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 456.096 |
|    value_loss_int       | 0.441 |
|    entropy_loss         | 1.389 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.460 |
|    explained_variance   | 0.011 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 180224 |
| Episodes                | 1313  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -23.6874 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 1559  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 544.320 |
|    value_loss_int       | 427.058 |
|    entropy_loss         | 1.310 |
|    rnd_loss             | 0.000 |
|    need_loss            | 389.039 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 184320 |
| Episodes                | 1350  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -26.2023 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1595  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.025 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 613.399 |
|    value_loss_int       | 2927.688 |
|    entropy_loss         | 1.263 |
|    rnd_loss             | 0.000 |
|    need_loss            | 2105.239 |
|    explained_variance   | 0.013 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 188416 |
| Episodes                | 1385  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 4.9438 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 1630  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 668.097 |
|    value_loss_int       | 5607.071 |
|    entropy_loss         | 1.272 |
|    rnd_loss             | 0.000 |
|    need_loss            | 2283.723 |
|    explained_variance   | 0.020 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 192512 |
| Episodes                | 1420  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -38.7613 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 1666  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 649.531 |
|    value_loss_int       | 5455.833 |
|    entropy_loss         | 1.324 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1372.294 |
|    explained_variance   | 0.024 |
|    beta (learned)       | 0.721 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 196608 |
| Episodes                | 1453  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 31.8861 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 1701  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 730.383 |
|    value_loss_int       | 3759.220 |
|    entropy_loss         | 1.395 |
|    rnd_loss             | 0.000 |
|    need_loss            | 518.647 |
|    explained_variance   | 0.036 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts200000.pt at timestep 200000
---------------------------------
| Timestep                | 200704 |
| Episodes                | 1483  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 58.4375 |
|    best_mean_reward     | 42.331 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 108.5 |
|    time_elapsed         | 1739  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.056 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 760.682 |
|    value_loss_int       | 2500.424 |
|    entropy_loss         | 1.413 |
|    rnd_loss             | 0.000 |
|    need_loss            | 279.430 |
|    explained_variance   | 0.034 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 200704
*** New best model saved! Mean reward: 58.437 ***
---------------------------------
| Timestep                | 204800 |
| Episodes                | 1512  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -18.4608 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1775  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.052 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 768.251 |
|    value_loss_int       | 969.017 |
|    entropy_loss         | 1.428 |
|    rnd_loss             | 0.000 |
|    need_loss            | 117.614 |
|    explained_variance   | 0.045 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 208896 |
| Episodes                | 1544  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 18.0376 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 1810  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.107 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 672.041 |
|    value_loss_int       | 388.988 |
|    entropy_loss         | 1.496 |
|    rnd_loss             | 0.000 |
|    need_loss            | 60.838 |
|    explained_variance   | 0.022 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 212992 |
| Episodes                | 1575  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 51.1256 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 1846  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.040 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 688.722 |
|    value_loss_int       | 324.228 |
|    entropy_loss         | 1.521 |
|    rnd_loss             | 0.000 |
|    need_loss            | 41.247 |
|    explained_variance   | 0.024 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 217088 |
| Episodes                | 1605  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 27.9663 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.3 |
|    time_elapsed         | 1880  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.048 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 702.687 |
|    value_loss_int       | 169.461 |
|    entropy_loss         | 1.496 |
|    rnd_loss             | 0.000 |
|    need_loss            | 24.864 |
|    explained_variance   | 0.044 |
|    beta (learned)       | 0.723 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 221184 |
| Episodes                | 1631  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 56.7213 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.7 |
|    time_elapsed         | 1914  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 670.546 |
|    value_loss_int       | 297.361 |
|    entropy_loss         | 1.518 |
|    rnd_loss             | 0.000 |
|    need_loss            | 30.321 |
|    explained_variance   | 0.040 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 225280 |
| Episodes                | 1661  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -45.1788 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.8 |
|    time_elapsed         | 1948  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.098 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 831.497 |
|    value_loss_int       | 77.921 |
|    entropy_loss         | 1.464 |
|    rnd_loss             | 0.000 |
|    need_loss            | 17.530 |
|    explained_variance   | 0.037 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 229376 |
| Episodes                | 1696  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -19.8798 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.7 |
|    time_elapsed         | 1982  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 719.824 |
|    value_loss_int       | 285.389 |
|    entropy_loss         | 1.427 |
|    rnd_loss             | 0.000 |
|    need_loss            | 35.853 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.713 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 233472 |
| Episodes                | 1730  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -21.5163 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 2017  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.041 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 664.051 |
|    value_loss_int       | 44.962 |
|    entropy_loss         | 1.360 |
|    rnd_loss             | 0.000 |
|    need_loss            | 14.410 |
|    explained_variance   | 0.011 |
|    beta (learned)       | 0.712 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 237568 |
| Episodes                | 1763  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 23.0459 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 2051  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.037 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 837.959 |
|    value_loss_int       | 280.661 |
|    entropy_loss         | 1.314 |
|    rnd_loss             | 0.000 |
|    need_loss            | 40.180 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.711 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 241664 |
| Episodes                | 1797  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -43.5313 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 2085  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.071 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 865.985 |
|    value_loss_int       | 64.556 |
|    entropy_loss         | 1.280 |
|    rnd_loss             | 0.000 |
|    need_loss            | 14.156 |
|    explained_variance   | 0.016 |
|    beta (learned)       | 0.710 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 245760 |
| Episodes                | 1829  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -44.7760 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 2119  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.052 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 732.435 |
|    value_loss_int       | 187.465 |
|    entropy_loss         | 1.195 |
|    rnd_loss             | 0.000 |
|    need_loss            | 24.187 |
|    explained_variance   | 0.010 |
|    beta (learned)       | 0.711 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 249856 |
| Episodes                | 1865  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -16.2963 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.0 |
|    time_elapsed         | 2154  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.029 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 696.803 |
|    value_loss_int       | 145.589 |
|    entropy_loss         | 1.251 |
|    rnd_loss             | 0.000 |
|    need_loss            | 18.220 |
|    explained_variance   | 0.005 |
|    beta (learned)       | 0.713 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts250000.pt at timestep 250000
---------------------------------
| Timestep                | 253952 |
| Episodes                | 1896  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 53.7273 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.8 |
|    time_elapsed         | 2190  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 725.085 |
|    value_loss_int       | 170.308 |
|    entropy_loss         | 1.315 |
|    rnd_loss             | 0.000 |
|    need_loss            | 19.467 |
|    explained_variance   | 0.018 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 258048 |
| Episodes                | 1929  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -36.3499 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 2225  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 688.746 |
|    value_loss_int       | 148.097 |
|    entropy_loss         | 1.333 |
|    rnd_loss             | 0.000 |
|    need_loss            | 17.028 |
|    explained_variance   | 0.033 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 262144 |
| Episodes                | 1963  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -45.2140 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 2261  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.034 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 728.595 |
|    value_loss_int       | 136.613 |
|    entropy_loss         | 1.276 |
|    rnd_loss             | 0.000 |
|    need_loss            | 16.351 |
|    explained_variance   | 0.010 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 266240 |
| Episodes                | 1997  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -97.8966 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 2296  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 631.704 |
|    value_loss_int       | 127.913 |
|    entropy_loss         | 1.342 |
|    rnd_loss             | 0.000 |
|    need_loss            | 15.694 |
|    explained_variance   | 0.005 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 270336 |
| Episodes                | 2035  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -55.8020 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 2331  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.034 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 659.715 |
|    value_loss_int       | 120.041 |
|    entropy_loss         | 1.325 |
|    rnd_loss             | 0.000 |
|    need_loss            | 15.290 |
|    explained_variance   | 0.004 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 274432 |
| Episodes                | 2069  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -42.2497 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 2366  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 582.509 |
|    value_loss_int       | 120.435 |
|    entropy_loss         | 1.330 |
|    rnd_loss             | 0.000 |
|    need_loss            | 14.770 |
|    explained_variance   | 0.011 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 278528 |
| Episodes                | 2096  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -12.0624 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.9 |
|    time_elapsed         | 2402  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.046 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 622.129 |
|    value_loss_int       | 124.926 |
|    entropy_loss         | 1.283 |
|    rnd_loss             | 0.000 |
|    need_loss            | 13.628 |
|    explained_variance   | 0.029 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 282624 |
| Episodes                | 2141  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -67.9742 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 2437  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.006 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 842.566 |
|    value_loss_int       | 95.842 |
|    entropy_loss         | 1.207 |
|    rnd_loss             | 0.000 |
|    need_loss            | 14.037 |
|    explained_variance   | -0.003 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 286720 |
| Episodes                | 2181  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -66.7429 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 2472  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.018 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 648.954 |
|    value_loss_int       | 91.488 |
|    entropy_loss         | 1.149 |
|    rnd_loss             | 0.000 |
|    need_loss            | 12.894 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 290816 |
| Episodes                | 2221  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -11.8486 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 2508  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.033 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 614.610 |
|    value_loss_int       | 85.914 |
|    entropy_loss         | 1.080 |
|    rnd_loss             | 0.000 |
|    need_loss            | 11.910 |
|    explained_variance   | 0.011 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 294912 |
| Episodes                | 2254  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -29.8992 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 2543  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.084 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 669.237 |
|    value_loss_int       | 79.573 |
|    entropy_loss         | 1.123 |
|    rnd_loss             | 0.000 |
|    need_loss            | 10.498 |
|    explained_variance   | 0.030 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 299008 |
| Episodes                | 2286  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -4.6103 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 2579  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.033 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 761.386 |
|    value_loss_int       | 64.412 |
|    entropy_loss         | 1.023 |
|    rnd_loss             | 0.000 |
|    need_loss            | 8.968 |
|    explained_variance   | 0.038 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts300000.pt at timestep 300000
---------------------------------
| Timestep                | 303104 |
| Episodes                | 2326  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -12.5434 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.7 |
|    time_elapsed         | 2615  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.042 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 731.289 |
|    value_loss_int       | 55.152 |
|    entropy_loss         | 1.015 |
|    rnd_loss             | 0.000 |
|    need_loss            | 8.677 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 307200 |
| Episodes                | 2362  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 38.7521 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.6 |
|    time_elapsed         | 2649  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 789.132 |
|    value_loss_int       | 47.676 |
|    entropy_loss         | 1.028 |
|    rnd_loss             | 0.000 |
|    need_loss            | 7.761 |
|    explained_variance   | 0.023 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 311296 |
| Episodes                | 2405  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -54.0270 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 2684  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.076 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 762.194 |
|    value_loss_int       | 42.842 |
|    entropy_loss         | 1.155 |
|    rnd_loss             | 0.000 |
|    need_loss            | 7.683 |
|    explained_variance   | -0.002 |
|    beta (learned)       | 0.716 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 315392 |
| Episodes                | 2437  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -35.4012 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 2718  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.058 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 703.677 |
|    value_loss_int       | 38.176 |
|    entropy_loss         | 1.175 |
|    rnd_loss             | 0.000 |
|    need_loss            | 6.550 |
|    explained_variance   | 0.031 |
|    beta (learned)       | 0.719 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 319488 |
| Episodes                | 2475  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -98.7811 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.6 |
|    time_elapsed         | 2752  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.068 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 794.053 |
|    value_loss_int       | 28.622 |
|    entropy_loss         | 1.206 |
|    rnd_loss             | 0.000 |
|    need_loss            | 5.676 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 323584 |
| Episodes                | 2510  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 36.2308 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 2786  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.026 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 907.963 |
|    value_loss_int       | 28.476 |
|    entropy_loss         | 1.257 |
|    rnd_loss             | 0.000 |
|    need_loss            | 5.773 |
|    explained_variance   | 0.051 |
|    beta (learned)       | 0.718 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 327680 |
| Episodes                | 2543  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 6.0695 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.7 |
|    time_elapsed         | 2820  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.070 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 812.115 |
|    value_loss_int       | 11.952 |
|    entropy_loss         | 1.228 |
|    rnd_loss             | 0.000 |
|    need_loss            | 3.554 |
|    explained_variance   | 0.067 |
|    beta (learned)       | 0.716 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 331776 |
| Episodes                | 2573  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 108.1055 |
|    best_mean_reward     | 58.437 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 2854  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 1092.430 |
|    value_loss_int       | 23.152 |
|    entropy_loss         | 1.229 |
|    rnd_loss             | 0.000 |
|    need_loss            | 4.801 |
|    explained_variance   | 0.053 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 331776
*** New best model saved! Mean reward: 108.105 ***
---------------------------------
| Timestep                | 335872 |
| Episodes                | 2606  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 10.6805 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 2889  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 940.516 |
|    value_loss_int       | 0.300 |
|    entropy_loss         | 1.177 |
|    rnd_loss             | 0.000 |
|    need_loss            | 1.608 |
|    explained_variance   | 0.029 |
|    beta (learned)       | 0.713 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 339968 |
| Episodes                | 2635  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 79.5243 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.6 |
|    time_elapsed         | 2923  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 955.500 |
|    value_loss_int       | 29.665 |
|    entropy_loss         | 1.178 |
|    rnd_loss             | 0.000 |
|    need_loss            | 11.583 |
|    explained_variance   | 0.035 |
|    beta (learned)       | 0.713 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 344064 |
| Episodes                | 2669  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 81.8169 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 2959  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 1118.984 |
|    value_loss_int       | 2.842 |
|    entropy_loss         | 1.094 |
|    rnd_loss             | 0.000 |
|    need_loss            | 2.619 |
|    explained_variance   | 0.026 |
|    beta (learned)       | 0.713 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 348160 |
| Episodes                | 2702  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -1.0000 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 2994  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.045 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 869.691 |
|    value_loss_int       | 103.296 |
|    entropy_loss         | 1.061 |
|    rnd_loss             | 0.000 |
|    need_loss            | 22.186 |
|    explained_variance   | 0.030 |
|    beta (learned)       | 0.710 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts350000.pt at timestep 350000
---------------------------------
| Timestep                | 352256 |
| Episodes                | 2733  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 50.7402 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 112.6 |
|    time_elapsed         | 3031  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.033 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 1004.427 |
|    value_loss_int       | 34.120 |
|    entropy_loss         | 0.981 |
|    rnd_loss             | 0.000 |
|    need_loss            | 7.273 |
|    explained_variance   | 0.028 |
|    beta (learned)       | 0.711 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 356352 |
| Episodes                | 2775  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -34.1181 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 3066  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.007 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 892.427 |
|    value_loss_int       | 54.606 |
|    entropy_loss         | 0.977 |
|    rnd_loss             | 0.000 |
|    need_loss            | 9.661 |
|    explained_variance   | 0.002 |
|    beta (learned)       | 0.712 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 360448 |
| Episodes                | 2813  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 7.6979 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 3102  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 816.241 |
|    value_loss_int       | 61.498 |
|    entropy_loss         | 1.037 |
|    rnd_loss             | 0.000 |
|    need_loss            | 10.129 |
|    explained_variance   | 0.021 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 364544 |
| Episodes                | 2844  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -14.5090 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3137  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.034 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 963.915 |
|    value_loss_int       | 50.260 |
|    entropy_loss         | 1.130 |
|    rnd_loss             | 0.000 |
|    need_loss            | 7.985 |
|    explained_variance   | 0.053 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 368640 |
| Episodes                | 2874  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 77.1874 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 3173  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 959.498 |
|    value_loss_int       | 54.887 |
|    entropy_loss         | 1.120 |
|    rnd_loss             | 0.000 |
|    need_loss            | 8.501 |
|    explained_variance   | 0.041 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 372736 |
| Episodes                | 2912  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 24.7243 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 3208  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.050 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 987.201 |
|    value_loss_int       | 47.050 |
|    entropy_loss         | 1.095 |
|    rnd_loss             | 0.000 |
|    need_loss            | 8.534 |
|    explained_variance   | 0.014 |
|    beta (learned)       | 0.714 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 376832 |
| Episodes                | 2943  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 66.0496 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3244  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.068 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 944.168 |
|    value_loss_int       | 29.109 |
|    entropy_loss         | 1.056 |
|    rnd_loss             | 0.000 |
|    need_loss            | 5.843 |
|    explained_variance   | 0.032 |
|    beta (learned)       | 0.712 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 380928 |
| Episodes                | 2980  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -60.4297 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 3279  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 898.816 |
|    value_loss_int       | 24.569 |
|    entropy_loss         | 1.109 |
|    rnd_loss             | 0.000 |
|    need_loss            | 5.478 |
|    explained_variance   | 0.014 |
|    beta (learned)       | 0.712 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 385024 |
| Episodes                | 3012  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -11.7132 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 3315  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.040 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 877.421 |
|    value_loss_int       | 15.099 |
|    entropy_loss         | 1.091 |
|    rnd_loss             | 0.000 |
|    need_loss            | 4.177 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 389120 |
| Episodes                | 3047  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -41.7949 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 3351  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 788.212 |
|    value_loss_int       | 15.397 |
|    entropy_loss         | 1.197 |
|    rnd_loss             | 0.000 |
|    need_loss            | 4.306 |
|    explained_variance   | 0.021 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 393216 |
| Episodes                | 3082  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -6.8311 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 3386  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.043 |
|    policy_loss          | -0.004 |
|    value_loss_ext       | 876.874 |
|    value_loss_int       | 7.232 |
|    entropy_loss         | 1.038 |
|    rnd_loss             | 0.000 |
|    need_loss            | 3.106 |
|    explained_variance   | 0.038 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 397312 |
| Episodes                | 3116  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -25.1828 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 3422  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 828.259 |
|    value_loss_int       | 6.687 |
|    entropy_loss         | 1.036 |
|    rnd_loss             | 0.000 |
|    need_loss            | 2.830 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.715 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts400000.pt at timestep 400000
---------------------------------
| Timestep                | 401408 |
| Episodes                | 3158  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -90.0614 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 112.9 |
|    time_elapsed         | 3458  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 723.039 |
|    value_loss_int       | 6.160 |
|    entropy_loss         | 0.927 |
|    rnd_loss             | 0.000 |
|    need_loss            | 0.321 |
|    explained_variance   | -0.029 |
|    beta (learned)       | 0.717 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 405504 |
| Episodes                | 3198  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -19.8702 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3494  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.001 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 728.350 |
|    value_loss_int       | 196.076 |
|    entropy_loss         | 0.962 |
|    rnd_loss             | 0.000 |
|    need_loss            | 126.571 |
|    explained_variance   | 0.007 |
|    beta (learned)       | 0.716 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 409600 |
| Episodes                | 3238  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -55.1045 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 3529  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 557.508 |
|    value_loss_int       | 192.376 |
|    entropy_loss         | 1.010 |
|    rnd_loss             | 0.000 |
|    need_loss            | 124.504 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 413696 |
| Episodes                | 3274  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -18.3590 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 3565  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.005 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 603.518 |
|    value_loss_int       | 192.655 |
|    entropy_loss         | 1.073 |
|    rnd_loss             | 0.000 |
|    need_loss            | 125.421 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 417792 |
| Episodes                | 3309  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -19.0638 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.1 |
|    time_elapsed         | 3601  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 655.701 |
|    value_loss_int       | 190.951 |
|    entropy_loss         | 1.153 |
|    rnd_loss             | 0.000 |
|    need_loss            | 124.797 |
|    explained_variance   | 0.018 |
|    beta (learned)       | 0.721 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 421888 |
| Episodes                | 3347  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -30.3977 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 3636  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.008 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 704.329 |
|    value_loss_int       | 184.490 |
|    entropy_loss         | 1.147 |
|    rnd_loss             | 0.000 |
|    need_loss            | 120.568 |
|    explained_variance   | 0.011 |
|    beta (learned)       | 0.723 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 425984 |
| Episodes                | 3387  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -71.6814 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.7 |
|    time_elapsed         | 3672  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 613.448 |
|    value_loss_int       | 178.889 |
|    entropy_loss         | 1.194 |
|    rnd_loss             | 0.000 |
|    need_loss            | 117.009 |
|    explained_variance   | 0.004 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 430080 |
| Episodes                | 3423  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -40.8495 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.1 |
|    time_elapsed         | 3708  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 605.287 |
|    value_loss_int       | 179.800 |
|    entropy_loss         | 1.256 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.484 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.720 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 434176 |
| Episodes                | 3457  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -45.3537 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3743  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 679.165 |
|    value_loss_int       | 178.732 |
|    entropy_loss         | 1.295 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.371 |
|    explained_variance   | 0.022 |
|    beta (learned)       | 0.719 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 438272 |
| Episodes                | 3494  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -52.7659 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 3779  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.033 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 609.223 |
|    value_loss_int       | 172.994 |
|    entropy_loss         | 1.342 |
|    rnd_loss             | 0.000 |
|    need_loss            | 114.671 |
|    explained_variance   | 0.024 |
|    beta (learned)       | 0.722 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 442368 |
| Episodes                | 3527  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 2.3174 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 3815  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 591.084 |
|    value_loss_int       | 174.519 |
|    entropy_loss         | 1.388 |
|    rnd_loss             | 0.000 |
|    need_loss            | 116.715 |
|    explained_variance   | 0.031 |
|    beta (learned)       | 0.724 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 446464 |
| Episodes                | 3562  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -42.6653 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 3850  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 626.257 |
|    value_loss_int       | 168.983 |
|    entropy_loss         | 1.346 |
|    rnd_loss             | 0.000 |
|    need_loss            | 113.387 |
|    explained_variance   | 0.021 |
|    beta (learned)       | 0.723 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts450000.pt at timestep 450000
---------------------------------
| Timestep                | 450560 |
| Episodes                | 3599  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -80.6990 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.1 |
|    time_elapsed         | 3886  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 677.643 |
|    value_loss_int       | 164.159 |
|    entropy_loss         | 1.327 |
|    rnd_loss             | 0.000 |
|    need_loss            | 110.475 |
|    explained_variance   | -0.001 |
|    beta (learned)       | 0.726 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 454656 |
| Episodes                | 3638  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -22.2803 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3922  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.026 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 629.136 |
|    value_loss_int       | 161.371 |
|    entropy_loss         | 1.303 |
|    rnd_loss             | 0.000 |
|    need_loss            | 109.066 |
|    explained_variance   | 0.014 |
|    beta (learned)       | 0.728 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 458752 |
| Episodes                | 3671  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 43.8864 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 3957  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.036 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 651.869 |
|    value_loss_int       | 162.599 |
|    entropy_loss         | 1.347 |
|    rnd_loss             | 0.000 |
|    need_loss            | 110.881 |
|    explained_variance   | 0.026 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 462848 |
| Episodes                | 3702  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 36.9790 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 3993  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 773.379 |
|    value_loss_int       | 162.504 |
|    entropy_loss         | 1.267 |
|    rnd_loss             | 0.000 |
|    need_loss            | 111.663 |
|    explained_variance   | 0.046 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 466944 |
| Episodes                | 3742  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -74.5125 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 4029  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.048 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 804.908 |
|    value_loss_int       | 151.662 |
|    entropy_loss         | 1.224 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.882 |
|    explained_variance   | 0.002 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 471040 |
| Episodes                | 3776  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 53.6723 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 4064  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.035 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 745.782 |
|    value_loss_int       | 154.276 |
|    entropy_loss         | 1.266 |
|    rnd_loss             | 0.000 |
|    need_loss            | 107.002 |
|    explained_variance   | 0.029 |
|    beta (learned)       | 0.728 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 475136 |
| Episodes                | 3811  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -4.7824 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 4100  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 767.699 |
|    value_loss_int       | 150.637 |
|    entropy_loss         | 1.201 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.227 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.730 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 479232 |
| Episodes                | 3852  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -33.1787 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 4135  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.030 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 840.227 |
|    value_loss_int       | 144.530 |
|    entropy_loss         | 1.144 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.331 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.730 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 483328 |
| Episodes                | 3888  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -3.5114 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.7 |
|    time_elapsed         | 4171  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.029 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 817.322 |
|    value_loss_int       | 145.431 |
|    entropy_loss         | 1.185 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.030 |
|    explained_variance   | 0.023 |
|    beta (learned)       | 0.730 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 487424 |
| Episodes                | 3920  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 76.6636 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 4207  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.035 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 920.236 |
|    value_loss_int       | 146.433 |
|    entropy_loss         | 1.165 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.051 |
|    explained_variance   | 0.033 |
|    beta (learned)       | 0.729 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 491520 |
| Episodes                | 3959  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -73.9762 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 4242  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.074 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 819.399 |
|    value_loss_int       | 138.388 |
|    entropy_loss         | 1.143 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.587 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.732 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 495616 |
| Episodes                | 3990  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 34.7362 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 4278  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 977.881 |
|    value_loss_int       | 142.912 |
|    entropy_loss         | 1.181 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.506 |
|    explained_variance   | 0.037 |
|    beta (learned)       | 0.732 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 499712 |
| Episodes                | 4022  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 35.3401 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 4313  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.084 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 950.720 |
|    value_loss_int       | 139.635 |
|    entropy_loss         | 1.207 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.701 |
|    explained_variance   | 0.028 |
|    beta (learned)       | 0.737 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts500000.pt at timestep 500000
---------------------------------
| Timestep                | 503808 |
| Episodes                | 4051  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 58.7443 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.4 |
|    time_elapsed         | 4349  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 966.458 |
|    value_loss_int       | 139.878 |
|    entropy_loss         | 1.234 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.773 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.737 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 507904 |
| Episodes                | 4080  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 115.9518 |
|    best_mean_reward     | 108.105 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 4385  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.032 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 1184.678 |
|    value_loss_int       | 138.024 |
|    entropy_loss         | 1.209 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.740 |
|    explained_variance   | 0.022 |
|    beta (learned)       | 0.734 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 507904
*** New best model saved! Mean reward: 115.952 ***
---------------------------------
| Timestep                | 512000 |
| Episodes                | 4114  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 38.7551 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 4423  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.041 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 921.267 |
|    value_loss_int       | 132.273 |
|    entropy_loss         | 1.100 |
|    rnd_loss             | 0.000 |
|    need_loss            | 102.245 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.736 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 516096 |
| Episodes                | 4147  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 53.9662 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 4458  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.034 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 1076.966 |
|    value_loss_int       | 130.857 |
|    entropy_loss         | 1.086 |
|    rnd_loss             | 0.000 |
|    need_loss            | 102.351 |
|    explained_variance   | 0.024 |
|    beta (learned)       | 0.737 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 520192 |
| Episodes                | 4187  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 33.7587 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 4494  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 1108.597 |
|    value_loss_int       | 124.568 |
|    entropy_loss         | 1.142 |
|    rnd_loss             | 0.000 |
|    need_loss            | 97.737 |
|    explained_variance   | 0.025 |
|    beta (learned)       | 0.739 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 524288 |
| Episodes                | 4220  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 54.2853 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.9 |
|    time_elapsed         | 4528  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 992.905 |
|    value_loss_int       | 127.740 |
|    entropy_loss         | 1.141 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.189 |
|    explained_variance   | 0.045 |
|    beta (learned)       | 0.739 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 528384 |
| Episodes                | 4254  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 35.7428 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.0 |
|    time_elapsed         | 4563  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 828.024 |
|    value_loss_int       | 124.206 |
|    entropy_loss         | 1.164 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.438 |
|    explained_variance   | 0.012 |
|    beta (learned)       | 0.740 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 532480 |
| Episodes                | 4296  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -34.0481 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.4 |
|    time_elapsed         | 4597  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 886.404 |
|    value_loss_int       | 117.065 |
|    entropy_loss         | 1.151 |
|    rnd_loss             | 0.000 |
|    need_loss            | 94.261 |
|    explained_variance   | 0.003 |
|    beta (learned)       | 0.740 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 536576 |
| Episodes                | 4337  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -70.8665 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.0 |
|    time_elapsed         | 4632  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.000 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 849.160 |
|    value_loss_int       | 116.862 |
|    entropy_loss         | 1.140 |
|    rnd_loss             | 0.000 |
|    need_loss            | 94.455 |
|    explained_variance   | 0.003 |
|    beta (learned)       | 0.740 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 540672 |
| Episodes                | 4372  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -29.3208 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.2 |
|    time_elapsed         | 4666  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 884.239 |
|    value_loss_int       | 119.470 |
|    entropy_loss         | 1.185 |
|    rnd_loss             | 0.000 |
|    need_loss            | 97.069 |
|    explained_variance   | 0.021 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 544768 |
| Episodes                | 4415  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -57.8888 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.0 |
|    time_elapsed         | 4701  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 691.189 |
|    value_loss_int       | 112.219 |
|    entropy_loss         | 1.216 |
|    rnd_loss             | 0.000 |
|    need_loss            | 91.031 |
|    explained_variance   | -0.021 |
|    beta (learned)       | 0.741 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 548864 |
| Episodes                | 4451  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -18.0869 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.2 |
|    time_elapsed         | 4736  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 693.056 |
|    value_loss_int       | 116.485 |
|    entropy_loss         | 1.242 |
|    rnd_loss             | 0.000 |
|    need_loss            | 95.190 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.741 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts550000.pt at timestep 550000
---------------------------------
| Timestep                | 552960 |
| Episodes                | 4488  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -55.6926 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 4771  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.030 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 688.675 |
|    value_loss_int       | 114.362 |
|    entropy_loss         | 1.244 |
|    rnd_loss             | 0.000 |
|    need_loss            | 93.830 |
|    explained_variance   | 0.016 |
|    beta (learned)       | 0.743 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 557056 |
| Episodes                | 4529  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -56.4233 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 4806  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.027 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 636.178 |
|    value_loss_int       | 109.343 |
|    entropy_loss         | 1.137 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.845 |
|    explained_variance   | -0.008 |
|    beta (learned)       | 0.745 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 561152 |
| Episodes                | 4570  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -25.3734 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 4842  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.060 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 725.099 |
|    value_loss_int       | 108.603 |
|    entropy_loss         | 1.247 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.606 |
|    explained_variance   | 0.005 |
|    beta (learned)       | 0.748 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 565248 |
| Episodes                | 4609  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -85.8888 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 4877  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.034 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 582.353 |
|    value_loss_int       | 108.255 |
|    entropy_loss         | 1.305 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.732 |
|    explained_variance   | -0.001 |
|    beta (learned)       | 0.748 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 569344 |
| Episodes                | 4642  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 19.0111 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 4913  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.040 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 625.664 |
|    value_loss_int       | 112.018 |
|    entropy_loss         | 1.300 |
|    rnd_loss             | 0.000 |
|    need_loss            | 93.541 |
|    explained_variance   | 0.028 |
|    beta (learned)       | 0.749 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 573440 |
| Episodes                | 4680  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -94.0801 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 4949  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 697.255 |
|    value_loss_int       | 106.633 |
|    entropy_loss         | 1.316 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.265 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.750 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 577536 |
| Episodes                | 4715  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -82.7223 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 4984  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 504.273 |
|    value_loss_int       | 107.238 |
|    entropy_loss         | 1.340 |
|    rnd_loss             | 0.000 |
|    need_loss            | 90.392 |
|    explained_variance   | -0.007 |
|    beta (learned)       | 0.750 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 581632 |
| Episodes                | 4752  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -1.0737 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 5020  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 694.035 |
|    value_loss_int       | 104.704 |
|    entropy_loss         | 1.296 |
|    rnd_loss             | 0.000 |
|    need_loss            | 88.622 |
|    explained_variance   | 0.006 |
|    beta (learned)       | 0.752 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 585728 |
| Episodes                | 4789  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -58.8038 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.2 |
|    time_elapsed         | 5056  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.038 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 601.492 |
|    value_loss_int       | 104.204 |
|    entropy_loss         | 1.361 |
|    rnd_loss             | 0.000 |
|    need_loss            | 88.707 |
|    explained_variance   | 0.006 |
|    beta (learned)       | 0.752 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 589824 |
| Episodes                | 4828  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -21.6102 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.6 |
|    time_elapsed         | 5091  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.055 |
|    policy_loss          | -0.003 |
|    value_loss_ext       | 639.446 |
|    value_loss_int       | 101.423 |
|    entropy_loss         | 1.365 |
|    rnd_loss             | 0.000 |
|    need_loss            | 86.723 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 593920 |
| Episodes                | 4868  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -87.6656 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.2 |
|    time_elapsed         | 5127  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 468.435 |
|    value_loss_int       | 99.265 |
|    entropy_loss         | 1.360 |
|    rnd_loss             | 0.000 |
|    need_loss            | 85.137 |
|    explained_variance   | -0.034 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 598016 |
| Episodes                | 4907  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -72.4407 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.5 |
|    time_elapsed         | 5163  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 578.151 |
|    value_loss_int       | 99.037 |
|    entropy_loss         | 1.415 |
|    rnd_loss             | 0.000 |
|    need_loss            | 85.342 |
|    explained_variance   | 0.002 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts600000.pt at timestep 600000
---------------------------------
| Timestep                | 602112 |
| Episodes                | 4948  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -52.6995 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.6 |
|    time_elapsed         | 5199  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 477.370 |
|    value_loss_int       | 96.799 |
|    entropy_loss         | 1.269 |
|    rnd_loss             | 0.000 |
|    need_loss            | 83.760 |
|    explained_variance   | -0.005 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 606208 |
| Episodes                | 4987  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -72.3297 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5235  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.037 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 465.637 |
|    value_loss_int       | 96.811 |
|    entropy_loss         | 1.254 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.237 |
|    explained_variance   | 0.002 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 610304 |
| Episodes                | 5024  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 9.8015 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 5270  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 609.235 |
|    value_loss_int       | 97.114 |
|    entropy_loss         | 1.227 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.997 |
|    explained_variance   | 0.017 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 614400 |
| Episodes                | 5065  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -64.0506 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 5305  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.036 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 601.883 |
|    value_loss_int       | 93.318 |
|    entropy_loss         | 1.219 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.113 |
|    explained_variance   | 0.003 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 618496 |
| Episodes                | 5107  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -63.9303 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 5341  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.064 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 494.550 |
|    value_loss_int       | 91.985 |
|    entropy_loss         | 1.258 |
|    rnd_loss             | 0.000 |
|    need_loss            | 81.473 |
|    explained_variance   | -0.009 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 622592 |
| Episodes                | 5144  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -73.4728 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 5376  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 488.844 |
|    value_loss_int       | 93.973 |
|    entropy_loss         | 1.368 |
|    rnd_loss             | 0.000 |
|    need_loss            | 83.853 |
|    explained_variance   | 0.006 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 626688 |
| Episodes                | 5183  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -62.2259 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5411  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.052 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 599.948 |
|    value_loss_int       | 92.226 |
|    entropy_loss         | 1.386 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.865 |
|    explained_variance   | 0.009 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 630784 |
| Episodes                | 5222  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -19.1363 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 5447  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.041 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 562.184 |
|    value_loss_int       | 91.047 |
|    entropy_loss         | 1.462 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.247 |
|    explained_variance   | 0.007 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 634880 |
| Episodes                | 5259  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -43.5343 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 5482  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 578.712 |
|    value_loss_int       | 91.084 |
|    entropy_loss         | 1.403 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.829 |
|    explained_variance   | 0.007 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 638976 |
| Episodes                | 5299  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -71.4945 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 5517  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.057 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 576.053 |
|    value_loss_int       | 88.098 |
|    entropy_loss         | 1.392 |
|    rnd_loss             | 0.000 |
|    need_loss            | 80.525 |
|    explained_variance   | 0.001 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 643072 |
| Episodes                | 5348  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -100.3774 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 5553  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.004 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 623.377 |
|    value_loss_int       | 82.293 |
|    entropy_loss         | 1.413 |
|    rnd_loss             | 0.000 |
|    need_loss            | 75.443 |
|    explained_variance   | -0.011 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 647168 |
| Episodes                | 5391  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -39.2396 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5588  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.048 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 459.964 |
|    value_loss_int       | 84.473 |
|    entropy_loss         | 1.564 |
|    rnd_loss             | 0.000 |
|    need_loss            | 77.904 |
|    explained_variance   | -0.008 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts650000.pt at timestep 650000
---------------------------------
| Timestep                | 651264 |
| Episodes                | 5430  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -53.0662 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 110.8 |
|    time_elapsed         | 5625  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 462.071 |
|    value_loss_int       | 86.153 |
|    entropy_loss         | 1.560 |
|    rnd_loss             | 0.000 |
|    need_loss            | 79.938 |
|    explained_variance   | -0.004 |
|    beta (learned)       | 0.759 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 655360 |
| Episodes                | 5481  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -97.3875 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 5661  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 416.325 |
|    value_loss_int       | 78.199 |
|    entropy_loss         | 1.600 |
|    rnd_loss             | 0.000 |
|    need_loss            | 72.736 |
|    explained_variance   | -0.015 |
|    beta (learned)       | 0.759 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 659456 |
| Episodes                | 5521  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -68.8803 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 5696  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 439.541 |
|    value_loss_int       | 84.116 |
|    entropy_loss         | 1.659 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.908 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 663552 |
| Episodes                | 5568  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -86.1211 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5731  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.008 |
|    clip_fraction        | 0.083 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 353.020 |
|    value_loss_int       | 78.811 |
|    entropy_loss         | 1.663 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.288 |
|    explained_variance   | 0.002 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 667648 |
| Episodes                | 5616  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -72.2524 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 5766  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 361.304 |
|    value_loss_int       | 77.747 |
|    entropy_loss         | 1.688 |
|    rnd_loss             | 0.000 |
|    need_loss            | 73.711 |
|    explained_variance   | 0.013 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 671744 |
| Episodes                | 5663  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -83.6268 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5802  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 296.257 |
|    value_loss_int       | 77.059 |
|    entropy_loss         | 1.715 |
|    rnd_loss             | 0.000 |
|    need_loss            | 73.578 |
|    explained_variance   | 0.029 |
|    beta (learned)       | 0.755 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 675840 |
| Episodes                | 5709  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -70.0669 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 5837  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 325.124 |
|    value_loss_int       | 76.778 |
|    entropy_loss         | 1.779 |
|    rnd_loss             | 0.000 |
|    need_loss            | 73.826 |
|    explained_variance   | 0.050 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 679936 |
| Episodes                | 5762  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -69.5329 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 5872  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 335.400 |
|    value_loss_int       | 72.459 |
|    entropy_loss         | 1.810 |
|    rnd_loss             | 0.000 |
|    need_loss            | 70.067 |
|    explained_variance   | 0.082 |
|    beta (learned)       | 0.756 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 684032 |
| Episodes                | 5814  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -49.0185 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 5908  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.052 |
|    policy_loss          | -0.004 |
|    value_loss_ext       | 378.941 |
|    value_loss_int       | 71.977 |
|    entropy_loss         | 1.713 |
|    rnd_loss             | 0.000 |
|    need_loss            | 70.116 |
|    explained_variance   | 0.104 |
|    beta (learned)       | 0.755 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 688128 |
| Episodes                | 5869  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -49.3340 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 5943  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.048 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 461.616 |
|    value_loss_int       | 70.519 |
|    entropy_loss         | 1.680 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.250 |
|    explained_variance   | 0.087 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 692224 |
| Episodes                | 5923  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -21.7769 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 5979  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 444.546 |
|    value_loss_int       | 69.639 |
|    entropy_loss         | 1.714 |
|    rnd_loss             | 0.000 |
|    need_loss            | 68.916 |
|    explained_variance   | 0.131 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 696320 |
| Episodes                | 5976  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -31.1811 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 6014  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 494.280 |
|    value_loss_int       | 69.164 |
|    entropy_loss         | 1.664 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.041 |
|    explained_variance   | 0.117 |
|    beta (learned)       | 0.755 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts700000.pt at timestep 700000
---------------------------------
| Timestep                | 700416 |
| Episodes                | 6035  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -2.2692 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 112.3 |
|    time_elapsed         | 6051  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 630.202 |
|    value_loss_int       | 65.630 |
|    entropy_loss         | 1.606 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.081 |
|    explained_variance   | 0.125 |
|    beta (learned)       | 0.752 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 704512 |
| Episodes                | 6094  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 40.7525 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 6086  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.065 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 818.449 |
|    value_loss_int       | 65.056 |
|    entropy_loss         | 1.417 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.047 |
|    explained_variance   | 0.091 |
|    beta (learned)       | 0.749 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 708608 |
| Episodes                | 6156  |
| rollout/                |       |
|    ep_rew_mean (ext)    | -10.2730 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.1 |
|    time_elapsed         | 6121  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.032 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 1060.052 |
|    value_loss_int       | 62.758 |
|    entropy_loss         | 1.335 |
|    rnd_loss             | 0.000 |
|    need_loss            | 64.237 |
|    explained_variance   | 0.115 |
|    beta (learned)       | 0.747 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 712704 |
| Episodes                | 6217  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 57.1186 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 6155  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 1318.492 |
|    value_loss_int       | 62.642 |
|    entropy_loss         | 1.344 |
|    rnd_loss             | 0.000 |
|    need_loss            | 64.745 |
|    explained_variance   | 0.082 |
|    beta (learned)       | 0.746 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 716800 |
| Episodes                | 6282  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 60.4502 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 6190  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.026 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 1423.837 |
|    value_loss_int       | 59.996 |
|    entropy_loss         | 1.247 |
|    rnd_loss             | 0.000 |
|    need_loss            | 62.735 |
|    explained_variance   | 0.043 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 720896 |
| Episodes                | 6345  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 54.4571 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.6 |
|    time_elapsed         | 6224  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 1755.537 |
|    value_loss_int       | 60.407 |
|    entropy_loss         | 1.142 |
|    rnd_loss             | 0.000 |
|    need_loss            | 63.878 |
|    explained_variance   | 0.048 |
|    beta (learned)       | 0.741 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 724992 |
| Episodes                | 6411  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 84.6642 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 6258  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2078.741 |
|    value_loss_int       | 58.182 |
|    entropy_loss         | 1.104 |
|    rnd_loss             | 0.000 |
|    need_loss            | 62.337 |
|    explained_variance   | 0.007 |
|    beta (learned)       | 0.741 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 729088 |
| Episodes                | 6472  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 76.8544 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.2 |
|    time_elapsed         | 6293  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2200.468 |
|    value_loss_int       | 60.007 |
|    entropy_loss         | 1.079 |
|    rnd_loss             | 0.000 |
|    need_loss            | 65.568 |
|    explained_variance   | 0.005 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 733184 |
| Episodes                | 6538  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 70.9375 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.8 |
|    time_elapsed         | 6327  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2520.572 |
|    value_loss_int       | 56.608 |
|    entropy_loss         | 0.956 |
|    rnd_loss             | 0.000 |
|    need_loss            | 63.605 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 737280 |
| Episodes                | 6601  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 58.4941 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 6361  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.043 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2574.497 |
|    value_loss_int       | 56.784 |
|    entropy_loss         | 0.985 |
|    rnd_loss             | 0.000 |
|    need_loss            | 65.063 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 741376 |
| Episodes                | 6664  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 150.2170 |
|    best_mean_reward     | 115.952 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 6396  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.032 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2481.071 |
|    value_loss_int       | 56.644 |
|    entropy_loss         | 0.896 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.044 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 741376
*** New best model saved! Mean reward: 150.217 ***
---------------------------------
| Timestep                | 745472 |
| Episodes                | 6732  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 106.6073 |
|    best_mean_reward     | 150.217 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 6432  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2456.189 |
|    value_loss_int       | 53.094 |
|    entropy_loss         | 0.880 |
|    rnd_loss             | 0.000 |
|    need_loss            | 63.243 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.741 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 749568 |
| Episodes                | 6797  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 89.4509 |
|    best_mean_reward     | 150.217 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 6467  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2521.468 |
|    value_loss_int       | 54.044 |
|    entropy_loss         | 0.878 |
|    rnd_loss             | 0.000 |
|    need_loss            | 65.346 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts750000.pt at timestep 750000
---------------------------------
| Timestep                | 753664 |
| Episodes                | 6862  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 100.2842 |
|    best_mean_reward     | 150.217 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.3 |
|    time_elapsed         | 6504  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2848.813 |
|    value_loss_int       | 53.116 |
|    entropy_loss         | 0.877 |
|    rnd_loss             | 0.000 |
|    need_loss            | 65.282 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.742 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 757760 |
| Episodes                | 6923  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 167.2734 |
|    best_mean_reward     | 150.217 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 6539  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2802.356 |
|    value_loss_int       | 54.310 |
|    entropy_loss         | 0.897 |
|    rnd_loss             | 0.000 |
|    need_loss            | 67.533 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 757760
*** New best model saved! Mean reward: 167.273 ***
---------------------------------
| Timestep                | 761856 |
| Episodes                | 6988  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 111.7492 |
|    best_mean_reward     | 167.273 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 6576  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.030 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2731.690 |
|    value_loss_int       | 51.939 |
|    entropy_loss         | 0.887 |
|    rnd_loss             | 0.000 |
|    need_loss            | 65.739 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 765952 |
| Episodes                | 7050  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 218.3254 |
|    best_mean_reward     | 167.273 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 6611  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3149.413 |
|    value_loss_int       | 52.880 |
|    entropy_loss         | 0.848 |
|    rnd_loss             | 0.000 |
|    need_loss            | 67.726 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 765952
*** New best model saved! Mean reward: 218.325 ***
---------------------------------
| Timestep                | 770048 |
| Episodes                | 7110  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 149.8937 |
|    best_mean_reward     | 218.325 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 6647  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2775.081 |
|    value_loss_int       | 53.158 |
|    entropy_loss         | 0.898 |
|    rnd_loss             | 0.000 |
|    need_loss            | 68.949 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.743 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 774144 |
| Episodes                | 7175  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 116.8200 |
|    best_mean_reward     | 218.325 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 6683  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2407.514 |
|    value_loss_int       | 50.127 |
|    entropy_loss         | 0.954 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.423 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.743 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 778240 |
| Episodes                | 7240  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 80.2865 |
|    best_mean_reward     | 218.325 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 6718  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.034 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2857.895 |
|    value_loss_int       | 49.973 |
|    entropy_loss         | 0.800 |
|    rnd_loss             | 0.000 |
|    need_loss            | 67.228 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 782336 |
| Episodes                | 7302  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 218.1559 |
|    best_mean_reward     | 218.325 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 6754  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.028 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3527.397 |
|    value_loss_int       | 50.829 |
|    entropy_loss         | 0.715 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.082 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.744 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 786432 |
| Episodes                | 7368  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 260.0608 |
|    best_mean_reward     | 218.325 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 6789  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3259.035 |
|    value_loss_int       | 47.936 |
|    entropy_loss         | 0.710 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.415 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.745 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 786432
*** New best model saved! Mean reward: 260.061 ***
---------------------------------
| Timestep                | 790528 |
| Episodes                | 7433  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 80.5460 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 6826  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3493.644 |
|    value_loss_int       | 48.103 |
|    entropy_loss         | 0.738 |
|    rnd_loss             | 0.000 |
|    need_loss            | 67.443 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.747 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 794624 |
| Episodes                | 7495  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 101.6441 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 6861  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3613.478 |
|    value_loss_int       | 48.808 |
|    entropy_loss         | 0.723 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.134 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.747 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 798720 |
| Episodes                | 7559  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 243.4388 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 6897  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3509.368 |
|    value_loss_int       | 47.544 |
|    entropy_loss         | 0.755 |
|    rnd_loss             | 0.000 |
|    need_loss            | 68.421 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.748 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts800000.pt at timestep 800000
---------------------------------
| Timestep                | 802816 |
| Episodes                | 7627  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 95.1715 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.1 |
|    time_elapsed         | 6933  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 3188.821 |
|    value_loss_int       | 44.887 |
|    entropy_loss         | 0.771 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.045 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.748 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 806912 |
| Episodes                | 7692  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 96.3183 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 6969  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3764.369 |
|    value_loss_int       | 46.000 |
|    entropy_loss         | 0.718 |
|    rnd_loss             | 0.000 |
|    need_loss            | 68.340 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.748 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 811008 |
| Episodes                | 7757  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 112.3747 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 7004  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3626.412 |
|    value_loss_int       | 45.499 |
|    entropy_loss         | 0.719 |
|    rnd_loss             | 0.000 |
|    need_loss            | 68.573 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.749 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 815104 |
| Episodes                | 7821  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 134.9507 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 7040  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3977.129 |
|    value_loss_int       | 45.861 |
|    entropy_loss         | 0.666 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.876 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.750 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 819200 |
| Episodes                | 7889  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 122.2329 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 7075  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3287.283 |
|    value_loss_int       | 42.887 |
|    entropy_loss         | 0.694 |
|    rnd_loss             | 0.000 |
|    need_loss            | 66.973 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.750 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 823296 |
| Episodes                | 7957  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 160.3084 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 7111  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3367.232 |
|    value_loss_int       | 42.768 |
|    entropy_loss         | 0.696 |
|    rnd_loss             | 0.000 |
|    need_loss            | 67.778 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.751 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 827392 |
| Episodes                | 8018  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 184.2075 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 7146  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4165.544 |
|    value_loss_int       | 44.976 |
|    entropy_loss         | 0.670 |
|    rnd_loss             | 0.000 |
|    need_loss            | 71.597 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.750 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 831488 |
| Episodes                | 8083  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 101.2442 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.9 |
|    time_elapsed         | 7181  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3415.252 |
|    value_loss_int       | 42.740 |
|    entropy_loss         | 0.749 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.527 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.753 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 835584 |
| Episodes                | 8145  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 145.9845 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 7215  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3701.278 |
|    value_loss_int       | 43.853 |
|    entropy_loss         | 0.800 |
|    rnd_loss             | 0.000 |
|    need_loss            | 71.987 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.753 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 839680 |
| Episodes                | 8208  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 130.2479 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 7250  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3474.504 |
|    value_loss_int       | 42.383 |
|    entropy_loss         | 0.722 |
|    rnd_loss             | 0.000 |
|    need_loss            | 70.979 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.753 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 843776 |
| Episodes                | 8265  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 308.5104 |
|    best_mean_reward     | 260.061 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 7284  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 4198.940 |
|    value_loss_int       | 44.652 |
|    entropy_loss         | 0.760 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.978 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.757 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 843776
*** New best model saved! Mean reward: 308.510 ***
---------------------------------
| Timestep                | 847872 |
| Episodes                | 8332  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 153.5331 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 7319  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3241.333 |
|    value_loss_int       | 40.016 |
|    entropy_loss         | 0.758 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.526 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.758 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts850000.pt at timestep 850000
---------------------------------
| Timestep                | 851968 |
| Episodes                | 8399  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 123.0965 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.6 |
|    time_elapsed         | 7354  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2990.373 |
|    value_loss_int       | 39.394 |
|    entropy_loss         | 0.793 |
|    rnd_loss             | 0.000 |
|    need_loss            | 69.753 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.760 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 856064 |
| Episodes                | 8463  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 81.2594 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 7388  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3321.861 |
|    value_loss_int       | 40.077 |
|    entropy_loss         | 0.695 |
|    rnd_loss             | 0.000 |
|    need_loss            | 71.788 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.759 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 860160 |
| Episodes                | 8524  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 142.4288 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.6 |
|    time_elapsed         | 7423  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3725.715 |
|    value_loss_int       | 40.969 |
|    entropy_loss         | 0.733 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.015 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.760 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 864256 |
| Episodes                | 8584  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 231.0773 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.6 |
|    time_elapsed         | 7457  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3499.657 |
|    value_loss_int       | 40.873 |
|    entropy_loss         | 0.732 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.859 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.761 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 868352 |
| Episodes                | 8649  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 155.7510 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 7493  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3575.357 |
|    value_loss_int       | 38.724 |
|    entropy_loss         | 0.698 |
|    rnd_loss             | 0.000 |
|    need_loss            | 72.679 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.760 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 872448 |
| Episodes                | 8719  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 112.3458 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 7528  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 3402.564 |
|    value_loss_int       | 36.664 |
|    entropy_loss         | 0.769 |
|    rnd_loss             | 0.000 |
|    need_loss            | 70.592 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.760 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 876544 |
| Episodes                | 8779  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 256.3388 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 7564  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3959.045 |
|    value_loss_int       | 39.674 |
|    entropy_loss         | 0.722 |
|    rnd_loss             | 0.000 |
|    need_loss            | 76.085 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.760 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 880640 |
| Episodes                | 8843  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 180.3035 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 7599  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3659.988 |
|    value_loss_int       | 37.901 |
|    entropy_loss         | 0.741 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.352 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.761 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 884736 |
| Episodes                | 8910  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 175.3761 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 7634  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3219.040 |
|    value_loss_int       | 36.054 |
|    entropy_loss         | 0.728 |
|    rnd_loss             | 0.000 |
|    need_loss            | 72.545 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.762 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 888832 |
| Episodes                | 8974  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.2282 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 7670  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3895.181 |
|    value_loss_int       | 36.851 |
|    entropy_loss         | 0.640 |
|    rnd_loss             | 0.000 |
|    need_loss            | 74.768 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.763 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 892928 |
| Episodes                | 9044  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 125.1621 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 7705  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2975.409 |
|    value_loss_int       | 34.102 |
|    entropy_loss         | 0.688 |
|    rnd_loss             | 0.000 |
|    need_loss            | 71.518 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.762 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 897024 |
| Episodes                | 9113  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 200.6185 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 7740  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3178.604 |
|    value_loss_int       | 34.105 |
|    entropy_loss         | 0.608 |
|    rnd_loss             | 0.000 |
|    need_loss            | 72.610 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.763 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts900000.pt at timestep 900000
---------------------------------
| Timestep                | 901120 |
| Episodes                | 9183  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 112.8384 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.0 |
|    time_elapsed         | 7777  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3364.007 |
|    value_loss_int       | 33.189 |
|    entropy_loss         | 0.581 |
|    rnd_loss             | 0.000 |
|    need_loss            | 72.167 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 905216 |
| Episodes                | 9247  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 160.8177 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 7812  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3984.297 |
|    value_loss_int       | 35.054 |
|    entropy_loss         | 0.590 |
|    rnd_loss             | 0.000 |
|    need_loss            | 76.089 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.765 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 909312 |
| Episodes                | 9313  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 257.2966 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 7847  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3809.197 |
|    value_loss_int       | 34.112 |
|    entropy_loss         | 0.594 |
|    rnd_loss             | 0.000 |
|    need_loss            | 75.410 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 913408 |
| Episodes                | 9379  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 210.2822 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 7882  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3515.579 |
|    value_loss_int       | 33.861 |
|    entropy_loss         | 0.725 |
|    rnd_loss             | 0.000 |
|    need_loss            | 75.924 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.765 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 917504 |
| Episodes                | 9444  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 244.8784 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 7918  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3793.559 |
|    value_loss_int       | 33.762 |
|    entropy_loss         | 0.718 |
|    rnd_loss             | 0.000 |
|    need_loss            | 76.756 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.766 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 921600 |
| Episodes                | 9511  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.5384 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 7953  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3424.808 |
|    value_loss_int       | 32.593 |
|    entropy_loss         | 0.686 |
|    rnd_loss             | 0.000 |
|    need_loss            | 75.817 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 925696 |
| Episodes                | 9580  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 123.8255 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 7988  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2709.654 |
|    value_loss_int       | 31.487 |
|    entropy_loss         | 0.754 |
|    rnd_loss             | 0.000 |
|    need_loss            | 75.076 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.763 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 929792 |
| Episodes                | 9644  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 166.9405 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 8024  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3954.182 |
|    value_loss_int       | 33.015 |
|    entropy_loss         | 0.752 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.771 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 933888 |
| Episodes                | 9709  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 163.3475 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 8059  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3504.306 |
|    value_loss_int       | 32.102 |
|    entropy_loss         | 0.723 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.137 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 937984 |
| Episodes                | 9774  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 176.4065 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 8094  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3587.791 |
|    value_loss_int       | 31.847 |
|    entropy_loss         | 0.621 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.624 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.764 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 942080 |
| Episodes                | 9842  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 117.3302 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 8129  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 3860.711 |
|    value_loss_int       | 30.707 |
|    entropy_loss         | 0.602 |
|    rnd_loss             | 0.000 |
|    need_loss            | 77.472 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.763 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 946176 |
| Episodes                | 9910  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 149.9878 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 8165  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4094.420 |
|    value_loss_int       | 30.144 |
|    entropy_loss         | 0.662 |
|    rnd_loss             | 0.000 |
|    need_loss            | 77.448 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.765 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts950000.pt at timestep 950000
---------------------------------
| Timestep                | 950272 |
| Episodes                | 9978  |
| rollout/                |       |
|    ep_rew_mean (ext)    | 97.2673 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.2 |
|    time_elapsed         | 8201  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3896.426 |
|    value_loss_int       | 30.479 |
|    entropy_loss         | 0.646 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.869 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.766 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 954368 |
| Episodes                | 10046 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 133.3790 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 8236  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3660.261 |
|    value_loss_int       | 29.819 |
|    entropy_loss         | 0.635 |
|    rnd_loss             | 0.000 |
|    need_loss            | 78.716 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.768 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 958464 |
| Episodes                | 10111 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 116.8137 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 8271  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3995.267 |
|    value_loss_int       | 30.465 |
|    entropy_loss         | 0.576 |
|    rnd_loss             | 0.000 |
|    need_loss            | 80.919 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.769 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 962560 |
| Episodes                | 10178 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 98.8600 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 8307  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3374.945 |
|    value_loss_int       | 29.062 |
|    entropy_loss         | 0.666 |
|    rnd_loss             | 0.000 |
|    need_loss            | 79.375 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.769 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 966656 |
| Episodes                | 10247 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 121.3237 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 8342  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3031.005 |
|    value_loss_int       | 28.322 |
|    entropy_loss         | 0.703 |
|    rnd_loss             | 0.000 |
|    need_loss            | 79.028 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.769 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 970752 |
| Episodes                | 10309 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 191.2895 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 8377  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4057.176 |
|    value_loss_int       | 30.582 |
|    entropy_loss         | 0.656 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.368 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.769 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 974848 |
| Episodes                | 10371 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 144.6831 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 8412  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4137.541 |
|    value_loss_int       | 30.013 |
|    entropy_loss         | 0.726 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.281 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.771 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 978944 |
| Episodes                | 10440 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 113.9144 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 8448  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3917.480 |
|    value_loss_int       | 27.774 |
|    entropy_loss         | 0.733 |
|    rnd_loss             | 0.000 |
|    need_loss            | 80.744 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.772 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 983040 |
| Episodes                | 10503 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 127.5510 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 8483  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3756.065 |
|    value_loss_int       | 28.962 |
|    entropy_loss         | 0.551 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.269 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.773 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 987136 |
| Episodes                | 10570 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 66.4210 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 8519  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3840.328 |
|    value_loss_int       | 27.530 |
|    entropy_loss         | 0.579 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.313 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.772 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 991232 |
| Episodes                | 10637 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 184.7893 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 8554  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.039 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3532.849 |
|    value_loss_int       | 26.967 |
|    entropy_loss         | 0.640 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.273 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.773 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 995328 |
| Episodes                | 10704 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 197.2969 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 8590  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.040 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3842.500 |
|    value_loss_int       | 26.885 |
|    entropy_loss         | 0.616 |
|    rnd_loss             | 0.000 |
|    need_loss            | 83.035 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.773 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 999424 |
| Episodes                | 10775 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 94.1872 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 8625  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.033 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3129.844 |
|    value_loss_int       | 25.151 |
|    entropy_loss         | 0.653 |
|    rnd_loss             | 0.000 |
|    need_loss            | 80.511 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.774 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1000000.pt at timestep 1000000
---------------------------------
| Timestep                | 1003520 |
| Episodes                | 10844 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 203.4873 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 8661  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3574.281 |
|    value_loss_int       | 25.620 |
|    entropy_loss         | 0.635 |
|    rnd_loss             | 0.000 |
|    need_loss            | 82.537 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.775 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1007616 |
| Episodes                | 10909 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 146.3018 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 8695  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.005 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4262.534 |
|    value_loss_int       | 26.743 |
|    entropy_loss         | 0.480 |
|    rnd_loss             | 0.000 |
|    need_loss            | 85.909 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.774 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1011712 |
| Episodes                | 10975 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 123.2349 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 8729  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3795.674 |
|    value_loss_int       | 26.214 |
|    entropy_loss         | 0.468 |
|    rnd_loss             | 0.000 |
|    need_loss            | 85.663 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.774 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1015808 |
| Episodes                | 11042 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 98.6087 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 8763  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4562.200 |
|    value_loss_int       | 25.819 |
|    entropy_loss         | 0.463 |
|    rnd_loss             | 0.000 |
|    need_loss            | 85.696 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.773 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1019904 |
| Episodes                | 11109 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 170.8736 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 8797  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.041 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4761.485 |
|    value_loss_int       | 25.645 |
|    entropy_loss         | 0.483 |
|    rnd_loss             | 0.000 |
|    need_loss            | 86.223 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.774 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1024000 |
| Episodes                | 11178 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 197.6751 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 8832  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.035 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4259.254 |
|    value_loss_int       | 24.349 |
|    entropy_loss         | 0.443 |
|    rnd_loss             | 0.000 |
|    need_loss            | 84.341 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.775 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1028096 |
| Episodes                | 11240 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 235.6248 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 8866  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4604.456 |
|    value_loss_int       | 26.533 |
|    entropy_loss         | 0.414 |
|    rnd_loss             | 0.000 |
|    need_loss            | 90.168 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1032192 |
| Episodes                | 11305 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 162.4207 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 8900  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4761.898 |
|    value_loss_int       | 25.262 |
|    entropy_loss         | 0.374 |
|    rnd_loss             | 0.000 |
|    need_loss            | 88.269 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1036288 |
| Episodes                | 11369 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 210.4493 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 8934  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4909.438 |
|    value_loss_int       | 25.223 |
|    entropy_loss         | 0.418 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.161 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.775 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1040384 |
| Episodes                | 11434 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 195.4610 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 8970  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4633.954 |
|    value_loss_int       | 24.790 |
|    entropy_loss         | 0.441 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.146 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.775 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1044480 |
| Episodes                | 11502 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 73.0915 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 9005  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4185.249 |
|    value_loss_int       | 24.031 |
|    entropy_loss         | 0.506 |
|    rnd_loss             | 0.000 |
|    need_loss            | 88.075 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.775 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1048576 |
| Episodes                | 11567 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 158.0990 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 9041  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3964.901 |
|    value_loss_int       | 24.071 |
|    entropy_loss         | 0.488 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.626 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1050000.pt at timestep 1050000
---------------------------------
| Timestep                | 1052672 |
| Episodes                | 11631 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 175.1857 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.2 |
|    time_elapsed         | 9077  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 4056.035 |
|    value_loss_int       | 24.659 |
|    entropy_loss         | 0.457 |
|    rnd_loss             | 0.000 |
|    need_loss            | 92.037 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1056768 |
| Episodes                | 11697 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 148.5644 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 9113  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 4434.142 |
|    value_loss_int       | 23.355 |
|    entropy_loss         | 0.422 |
|    rnd_loss             | 0.000 |
|    need_loss            | 89.989 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1060864 |
| Episodes                | 11761 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 264.9499 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 9148  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.042 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4318.643 |
|    value_loss_int       | 24.062 |
|    entropy_loss         | 0.548 |
|    rnd_loss             | 0.000 |
|    need_loss            | 92.672 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1064960 |
| Episodes                | 11825 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 195.8879 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 9184  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4472.884 |
|    value_loss_int       | 23.843 |
|    entropy_loss         | 0.552 |
|    rnd_loss             | 0.000 |
|    need_loss            | 93.227 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1069056 |
| Episodes                | 11892 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 198.7510 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 9219  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.032 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 3809.588 |
|    value_loss_int       | 22.426 |
|    entropy_loss         | 0.597 |
|    rnd_loss             | 0.000 |
|    need_loss            | 90.734 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1073152 |
| Episodes                | 11956 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 218.1690 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 9255  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4389.944 |
|    value_loss_int       | 23.647 |
|    entropy_loss         | 0.525 |
|    rnd_loss             | 0.000 |
|    need_loss            | 94.692 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1077248 |
| Episodes                | 12024 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 192.0318 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 9290  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3967.413 |
|    value_loss_int       | 21.800 |
|    entropy_loss         | 0.488 |
|    rnd_loss             | 0.000 |
|    need_loss            | 91.138 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1081344 |
| Episodes                | 12091 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 154.7685 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 9326  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4424.415 |
|    value_loss_int       | 21.786 |
|    entropy_loss         | 0.540 |
|    rnd_loss             | 0.000 |
|    need_loss            | 92.196 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1085440 |
| Episodes                | 12158 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 254.4710 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 9361  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 4231.760 |
|    value_loss_int       | 21.687 |
|    entropy_loss         | 0.518 |
|    rnd_loss             | 0.000 |
|    need_loss            | 92.860 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1089536 |
| Episodes                | 12222 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 243.5658 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 9396  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4792.640 |
|    value_loss_int       | 12.684 |
|    entropy_loss         | 0.539 |
|    rnd_loss             | 0.000 |
|    need_loss            | 95.880 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1093632 |
| Episodes                | 12288 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 179.9050 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 9432  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4372.980 |
|    value_loss_int       | 13.064 |
|    entropy_loss         | 0.561 |
|    rnd_loss             | 0.000 |
|    need_loss            | 144.116 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.777 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1097728 |
| Episodes                | 12357 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 154.9369 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 9467  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.005 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4043.912 |
|    value_loss_int       | 13.683 |
|    entropy_loss         | 0.543 |
|    rnd_loss             | 0.000 |
|    need_loss            | 173.463 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1100000.pt at timestep 1100000
---------------------------------
| Timestep                | 1101824 |
| Episodes                | 12422 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.6064 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.7 |
|    time_elapsed         | 9503  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.002 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4072.036 |
|    value_loss_int       | 11.904 |
|    entropy_loss         | 0.501 |
|    rnd_loss             | 0.000 |
|    need_loss            | 179.124 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.776 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1105920 |
| Episodes                | 12492 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.1908 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.5 |
|    time_elapsed         | 9538  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3958.089 |
|    value_loss_int       | 11.844 |
|    entropy_loss         | 0.536 |
|    rnd_loss             | 0.000 |
|    need_loss            | 183.045 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1110016 |
| Episodes                | 12563 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 155.8617 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 9573  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3594.527 |
|    value_loss_int       | 9.711 |
|    entropy_loss         | 0.546 |
|    rnd_loss             | 0.000 |
|    need_loss            | 177.262 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1114112 |
| Episodes                | 12630 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 119.2039 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 9607  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.035 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4261.437 |
|    value_loss_int       | 10.131 |
|    entropy_loss         | 0.550 |
|    rnd_loss             | 0.000 |
|    need_loss            | 168.289 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1118208 |
| Episodes                | 12695 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 245.8286 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 9641  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4166.798 |
|    value_loss_int       | 9.920 |
|    entropy_loss         | 0.555 |
|    rnd_loss             | 0.000 |
|    need_loss            | 166.926 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1122304 |
| Episodes                | 12758 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 164.6603 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 9675  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4461.249 |
|    value_loss_int       | 10.538 |
|    entropy_loss         | 0.522 |
|    rnd_loss             | 0.000 |
|    need_loss            | 179.562 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1126400 |
| Episodes                | 12822 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 179.3292 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 9709  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4457.527 |
|    value_loss_int       | 11.370 |
|    entropy_loss         | 0.525 |
|    rnd_loss             | 0.000 |
|    need_loss            | 182.128 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1130496 |
| Episodes                | 12893 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 181.9996 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 9744  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4093.340 |
|    value_loss_int       | 12.106 |
|    entropy_loss         | 0.585 |
|    rnd_loss             | 0.000 |
|    need_loss            | 178.547 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1134592 |
| Episodes                | 12960 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 244.9574 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 9778  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4018.974 |
|    value_loss_int       | 10.345 |
|    entropy_loss         | 0.582 |
|    rnd_loss             | 0.000 |
|    need_loss            | 173.445 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1138688 |
| Episodes                | 13022 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 160.3699 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 9812  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4226.240 |
|    value_loss_int       | 11.039 |
|    entropy_loss         | 0.600 |
|    rnd_loss             | 0.000 |
|    need_loss            | 176.866 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1142784 |
| Episodes                | 13089 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 95.2233 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.1 |
|    time_elapsed         | 9847  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3773.332 |
|    value_loss_int       | 11.172 |
|    entropy_loss         | 0.606 |
|    rnd_loss             | 0.000 |
|    need_loss            | 180.922 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1146880 |
| Episodes                | 13155 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 151.7458 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 9883  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4053.932 |
|    value_loss_int       | 10.595 |
|    entropy_loss         | 0.547 |
|    rnd_loss             | 0.000 |
|    need_loss            | 174.009 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1150000.pt at timestep 1150000
---------------------------------
| Timestep                | 1150976 |
| Episodes                | 13221 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 258.9769 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.7 |
|    time_elapsed         | 9919  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.050 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3928.575 |
|    value_loss_int       | 10.603 |
|    entropy_loss         | 0.600 |
|    rnd_loss             | 0.000 |
|    need_loss            | 174.962 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1155072 |
| Episodes                | 13286 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 149.3816 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 9954  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3575.227 |
|    value_loss_int       | 10.252 |
|    entropy_loss         | 0.628 |
|    rnd_loss             | 0.000 |
|    need_loss            | 175.063 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1159168 |
| Episodes                | 13352 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 118.7959 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 9989  |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3914.985 |
|    value_loss_int       | 10.115 |
|    entropy_loss         | 0.617 |
|    rnd_loss             | 0.000 |
|    need_loss            | 172.624 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1163264 |
| Episodes                | 13417 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 192.6419 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 10025 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3871.894 |
|    value_loss_int       | 10.270 |
|    entropy_loss         | 0.600 |
|    rnd_loss             | 0.000 |
|    need_loss            | 172.085 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1167360 |
| Episodes                | 13477 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 129.7545 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 10060 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4543.544 |
|    value_loss_int       | 10.857 |
|    entropy_loss         | 0.575 |
|    rnd_loss             | 0.000 |
|    need_loss            | 172.025 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1171456 |
| Episodes                | 13544 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 101.7313 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 10095 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3748.304 |
|    value_loss_int       | 10.836 |
|    entropy_loss         | 0.635 |
|    rnd_loss             | 0.000 |
|    need_loss            | 180.271 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1175552 |
| Episodes                | 13609 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 171.6090 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 10131 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4039.520 |
|    value_loss_int       | 10.532 |
|    entropy_loss         | 0.616 |
|    rnd_loss             | 0.000 |
|    need_loss            | 173.399 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1179648 |
| Episodes                | 13670 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 163.8238 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 10166 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 4067.957 |
|    value_loss_int       | 10.818 |
|    entropy_loss         | 0.572 |
|    rnd_loss             | 0.000 |
|    need_loss            | 170.040 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1183744 |
| Episodes                | 13738 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 200.6952 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 10202 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4024.662 |
|    value_loss_int       | 10.464 |
|    entropy_loss         | 0.588 |
|    rnd_loss             | 0.000 |
|    need_loss            | 172.294 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1187840 |
| Episodes                | 13800 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 178.8385 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 10237 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4467.767 |
|    value_loss_int       | 10.210 |
|    entropy_loss         | 0.529 |
|    rnd_loss             | 0.000 |
|    need_loss            | 166.025 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1191936 |
| Episodes                | 13866 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.2428 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 10272 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.036 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3603.178 |
|    value_loss_int       | 9.846 |
|    entropy_loss         | 0.597 |
|    rnd_loss             | 0.000 |
|    need_loss            | 167.943 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1196032 |
| Episodes                | 13927 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 180.6448 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 10308 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4040.549 |
|    value_loss_int       | 10.631 |
|    entropy_loss         | 0.607 |
|    rnd_loss             | 0.000 |
|    need_loss            | 171.818 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1200000.pt at timestep 1200000
---------------------------------
| Timestep                | 1200128 |
| Episodes                | 13992 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 164.4409 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.8 |
|    time_elapsed         | 10344 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3580.584 |
|    value_loss_int       | 10.411 |
|    entropy_loss         | 0.670 |
|    rnd_loss             | 0.000 |
|    need_loss            | 171.549 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1204224 |
| Episodes                | 14058 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 115.1927 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 10379 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3320.440 |
|    value_loss_int       | 10.353 |
|    entropy_loss         | 0.673 |
|    rnd_loss             | 0.000 |
|    need_loss            | 168.190 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1208320 |
| Episodes                | 14125 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 210.0837 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.7 |
|    time_elapsed         | 10414 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3313.061 |
|    value_loss_int       | 9.988 |
|    entropy_loss         | 0.676 |
|    rnd_loss             | 0.000 |
|    need_loss            | 165.843 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1212416 |
| Episodes                | 14186 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 313.1215 |
|    best_mean_reward     | 308.510 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 10448 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4199.645 |
|    value_loss_int       | 11.052 |
|    entropy_loss         | 0.651 |
|    rnd_loss             | 0.000 |
|    need_loss            | 165.609 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_best.pt at timestep 1212416
*** New best model saved! Mean reward: 313.121 ***
---------------------------------
| Timestep                | 1216512 |
| Episodes                | 14254 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 91.3914 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.5 |
|    time_elapsed         | 10483 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2868.250 |
|    value_loss_int       | 9.679 |
|    entropy_loss         | 0.762 |
|    rnd_loss             | 0.000 |
|    need_loss            | 165.867 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1220608 |
| Episodes                | 14321 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 154.9879 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 10517 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3227.648 |
|    value_loss_int       | 9.256 |
|    entropy_loss         | 0.772 |
|    rnd_loss             | 0.000 |
|    need_loss            | 163.712 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1224704 |
| Episodes                | 14389 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 85.3701 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.9 |
|    time_elapsed         | 10551 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2928.610 |
|    value_loss_int       | 9.121 |
|    entropy_loss         | 0.797 |
|    rnd_loss             | 0.000 |
|    need_loss            | 158.618 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1228800 |
| Episodes                | 14454 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 112.0331 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 10586 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2833.331 |
|    value_loss_int       | 9.169 |
|    entropy_loss         | 0.904 |
|    rnd_loss             | 0.000 |
|    need_loss            | 151.537 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1232896 |
| Episodes                | 14515 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.4274 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 10620 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3386.193 |
|    value_loss_int       | 10.404 |
|    entropy_loss         | 0.821 |
|    rnd_loss             | 0.000 |
|    need_loss            | 162.540 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1236992 |
| Episodes                | 14575 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 71.7179 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 10654 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3292.039 |
|    value_loss_int       | 11.081 |
|    entropy_loss         | 0.810 |
|    rnd_loss             | 0.000 |
|    need_loss            | 169.793 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1241088 |
| Episodes                | 14640 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 157.0693 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.8 |
|    time_elapsed         | 10689 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2881.131 |
|    value_loss_int       | 10.534 |
|    entropy_loss         | 0.799 |
|    rnd_loss             | 0.000 |
|    need_loss            | 168.729 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1245184 |
| Episodes                | 14701 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 129.0744 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 10725 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3336.857 |
|    value_loss_int       | 10.414 |
|    entropy_loss         | 0.780 |
|    rnd_loss             | 0.000 |
|    need_loss            | 169.722 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1249280 |
| Episodes                | 14766 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.5597 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 10760 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2734.851 |
|    value_loss_int       | 10.082 |
|    entropy_loss         | 0.812 |
|    rnd_loss             | 0.000 |
|    need_loss            | 169.456 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1250000.pt at timestep 1250000
---------------------------------
| Timestep                | 1253376 |
| Episodes                | 14831 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 181.8973 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.4 |
|    time_elapsed         | 10797 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3004.972 |
|    value_loss_int       | 10.115 |
|    entropy_loss         | 0.806 |
|    rnd_loss             | 0.000 |
|    need_loss            | 165.184 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1257472 |
| Episodes                | 14892 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.0193 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 10832 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3508.894 |
|    value_loss_int       | 10.194 |
|    entropy_loss         | 0.771 |
|    rnd_loss             | 0.000 |
|    need_loss            | 165.836 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1261568 |
| Episodes                | 14952 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 225.1902 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 10868 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3542.861 |
|    value_loss_int       | 10.556 |
|    entropy_loss         | 0.759 |
|    rnd_loss             | 0.000 |
|    need_loss            | 167.772 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1265664 |
| Episodes                | 15013 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 161.8082 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 10903 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3300.627 |
|    value_loss_int       | 10.418 |
|    entropy_loss         | 0.698 |
|    rnd_loss             | 0.000 |
|    need_loss            | 173.659 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1269760 |
| Episodes                | 15076 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 142.9595 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 10939 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3407.582 |
|    value_loss_int       | 10.322 |
|    entropy_loss         | 0.696 |
|    rnd_loss             | 0.000 |
|    need_loss            | 167.852 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1273856 |
| Episodes                | 15141 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 221.7318 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.1 |
|    time_elapsed         | 10974 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3433.130 |
|    value_loss_int       | 9.705 |
|    entropy_loss         | 0.739 |
|    rnd_loss             | 0.000 |
|    need_loss            | 161.130 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1277952 |
| Episodes                | 15201 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 125.5281 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 11010 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3526.586 |
|    value_loss_int       | 9.881 |
|    entropy_loss         | 0.730 |
|    rnd_loss             | 0.000 |
|    need_loss            | 161.101 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1282048 |
| Episodes                | 15266 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 144.4620 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.4 |
|    time_elapsed         | 11046 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.005 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3892.158 |
|    value_loss_int       | 9.967 |
|    entropy_loss         | 0.739 |
|    rnd_loss             | 0.000 |
|    need_loss            | 162.764 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1286144 |
| Episodes                | 15330 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 181.6569 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 11081 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3550.619 |
|    value_loss_int       | 9.849 |
|    entropy_loss         | 0.672 |
|    rnd_loss             | 0.000 |
|    need_loss            | 158.952 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1290240 |
| Episodes                | 15390 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 160.7781 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 11116 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3812.829 |
|    value_loss_int       | 9.763 |
|    entropy_loss         | 0.650 |
|    rnd_loss             | 0.000 |
|    need_loss            | 161.960 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1294336 |
| Episodes                | 15456 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 110.6120 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 11152 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.004 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3623.612 |
|    value_loss_int       | 10.109 |
|    entropy_loss         | 0.652 |
|    rnd_loss             | 0.000 |
|    need_loss            | 162.891 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1298432 |
| Episodes                | 15521 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 210.3947 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.5 |
|    time_elapsed         | 11187 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3148.723 |
|    value_loss_int       | 9.547 |
|    entropy_loss         | 0.625 |
|    rnd_loss             | 0.000 |
|    need_loss            | 160.534 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1300000.pt at timestep 1300000
---------------------------------
| Timestep                | 1302528 |
| Episodes                | 15581 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 129.7541 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.3 |
|    time_elapsed         | 11222 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4223.912 |
|    value_loss_int       | 10.514 |
|    entropy_loss         | 0.603 |
|    rnd_loss             | 0.000 |
|    need_loss            | 161.148 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1306624 |
| Episodes                | 15652 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 77.1125 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 11256 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3229.510 |
|    value_loss_int       | 9.735 |
|    entropy_loss         | 0.645 |
|    rnd_loss             | 0.000 |
|    need_loss            | 158.342 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1310720 |
| Episodes                | 15717 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 143.6514 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 11290 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3684.358 |
|    value_loss_int       | 8.857 |
|    entropy_loss         | 0.661 |
|    rnd_loss             | 0.000 |
|    need_loss            | 151.790 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1314816 |
| Episodes                | 15778 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 124.0019 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 11324 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4106.945 |
|    value_loss_int       | 9.622 |
|    entropy_loss         | 0.653 |
|    rnd_loss             | 0.000 |
|    need_loss            | 150.942 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1318912 |
| Episodes                | 15843 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 65.8388 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 11359 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3346.745 |
|    value_loss_int       | 9.544 |
|    entropy_loss         | 0.758 |
|    rnd_loss             | 0.000 |
|    need_loss            | 154.491 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1323008 |
| Episodes                | 15907 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.6435 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 119.6 |
|    time_elapsed         | 11393 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3765.872 |
|    value_loss_int       | 10.136 |
|    entropy_loss         | 0.784 |
|    rnd_loss             | 0.000 |
|    need_loss            | 153.513 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1327104 |
| Episodes                | 15972 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 47.4981 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 11427 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3039.092 |
|    value_loss_int       | 9.890 |
|    entropy_loss         | 0.820 |
|    rnd_loss             | 0.000 |
|    need_loss            | 154.411 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1331200 |
| Episodes                | 16034 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 139.3727 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.6 |
|    time_elapsed         | 11462 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3100.052 |
|    value_loss_int       | 9.743 |
|    entropy_loss         | 0.830 |
|    rnd_loss             | 0.000 |
|    need_loss            | 154.710 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1335296 |
| Episodes                | 16098 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 159.2201 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 11497 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3278.018 |
|    value_loss_int       | 9.150 |
|    entropy_loss         | 0.796 |
|    rnd_loss             | 0.000 |
|    need_loss            | 152.514 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1339392 |
| Episodes                | 16160 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 77.1481 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 11533 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3345.982 |
|    value_loss_int       | 9.422 |
|    entropy_loss         | 0.817 |
|    rnd_loss             | 0.000 |
|    need_loss            | 149.116 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1343488 |
| Episodes                | 16226 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 103.0116 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 11568 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2821.590 |
|    value_loss_int       | 9.954 |
|    entropy_loss         | 0.845 |
|    rnd_loss             | 0.000 |
|    need_loss            | 152.590 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1347584 |
| Episodes                | 16297 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 109.3935 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 11603 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2169.821 |
|    value_loss_int       | 7.753 |
|    entropy_loss         | 0.954 |
|    rnd_loss             | 0.000 |
|    need_loss            | 143.815 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1350000.pt at timestep 1350000
---------------------------------
| Timestep                | 1351680 |
| Episodes                | 16357 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 144.8930 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.3 |
|    time_elapsed         | 11640 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3053.587 |
|    value_loss_int       | 8.143 |
|    entropy_loss         | 0.922 |
|    rnd_loss             | 0.000 |
|    need_loss            | 138.414 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1355776 |
| Episodes                | 16420 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 132.4316 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 11675 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2492.606 |
|    value_loss_int       | 8.477 |
|    entropy_loss         | 1.019 |
|    rnd_loss             | 0.000 |
|    need_loss            | 145.617 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1359872 |
| Episodes                | 16483 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 92.6233 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 11711 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2718.403 |
|    value_loss_int       | 9.600 |
|    entropy_loss         | 1.048 |
|    rnd_loss             | 0.000 |
|    need_loss            | 147.461 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1363968 |
| Episodes                | 16542 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 121.3890 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 11746 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2579.616 |
|    value_loss_int       | 8.810 |
|    entropy_loss         | 0.986 |
|    rnd_loss             | 0.000 |
|    need_loss            | 150.455 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1368064 |
| Episodes                | 16601 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 102.1220 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 11781 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2517.407 |
|    value_loss_int       | 9.378 |
|    entropy_loss         | 0.956 |
|    rnd_loss             | 0.000 |
|    need_loss            | 156.140 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1372160 |
| Episodes                | 16663 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 106.2885 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 11817 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2835.849 |
|    value_loss_int       | 10.246 |
|    entropy_loss         | 0.947 |
|    rnd_loss             | 0.000 |
|    need_loss            | 160.046 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1376256 |
| Episodes                | 16727 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 97.9830 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 11852 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2631.738 |
|    value_loss_int       | 9.802 |
|    entropy_loss         | 0.950 |
|    rnd_loss             | 0.000 |
|    need_loss            | 156.333 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1380352 |
| Episodes                | 16786 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 206.1682 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 11887 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2811.430 |
|    value_loss_int       | 9.302 |
|    entropy_loss         | 0.969 |
|    rnd_loss             | 0.000 |
|    need_loss            | 155.919 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1384448 |
| Episodes                | 16851 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 136.0972 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 11922 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2242.230 |
|    value_loss_int       | 9.239 |
|    entropy_loss         | 1.033 |
|    rnd_loss             | 0.000 |
|    need_loss            | 155.897 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1388544 |
| Episodes                | 16911 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 142.7361 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 11956 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2878.149 |
|    value_loss_int       | 9.307 |
|    entropy_loss         | 1.031 |
|    rnd_loss             | 0.000 |
|    need_loss            | 152.442 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1392640 |
| Episodes                | 16977 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 102.7138 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 11990 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2189.242 |
|    value_loss_int       | 8.670 |
|    entropy_loss         | 1.064 |
|    rnd_loss             | 0.000 |
|    need_loss            | 150.568 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1396736 |
| Episodes                | 17038 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 158.0713 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 12024 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2638.052 |
|    value_loss_int       | 8.820 |
|    entropy_loss         | 0.987 |
|    rnd_loss             | 0.000 |
|    need_loss            | 148.803 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1400000.pt at timestep 1400000
---------------------------------
| Timestep                | 1400832 |
| Episodes                | 17104 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 97.4902 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.4 |
|    time_elapsed         | 12059 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2358.904 |
|    value_loss_int       | 8.518 |
|    entropy_loss         | 0.982 |
|    rnd_loss             | 0.000 |
|    need_loss            | 144.326 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1404928 |
| Episodes                | 17170 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 133.5454 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 12093 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2582.270 |
|    value_loss_int       | 8.066 |
|    entropy_loss         | 0.930 |
|    rnd_loss             | 0.000 |
|    need_loss            | 139.821 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1409024 |
| Episodes                | 17232 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 163.8590 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 12128 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2741.277 |
|    value_loss_int       | 8.041 |
|    entropy_loss         | 0.962 |
|    rnd_loss             | 0.000 |
|    need_loss            | 140.025 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1413120 |
| Episodes                | 17297 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 106.8331 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.6 |
|    time_elapsed         | 12162 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2708.823 |
|    value_loss_int       | 8.067 |
|    entropy_loss         | 0.939 |
|    rnd_loss             | 0.000 |
|    need_loss            | 140.552 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1417216 |
| Episodes                | 17363 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 211.7083 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.2 |
|    time_elapsed         | 12196 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3141.730 |
|    value_loss_int       | 9.652 |
|    entropy_loss         | 0.918 |
|    rnd_loss             | 0.000 |
|    need_loss            | 138.931 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1421312 |
| Episodes                | 17428 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 137.8311 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 12232 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2779.838 |
|    value_loss_int       | 8.361 |
|    entropy_loss         | 0.965 |
|    rnd_loss             | 0.000 |
|    need_loss            | 141.912 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1425408 |
| Episodes                | 17487 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 198.0129 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 12267 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2707.031 |
|    value_loss_int       | 8.715 |
|    entropy_loss         | 0.937 |
|    rnd_loss             | 0.000 |
|    need_loss            | 144.296 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1429504 |
| Episodes                | 17545 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 133.6812 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 12303 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3015.974 |
|    value_loss_int       | 9.131 |
|    entropy_loss         | 0.904 |
|    rnd_loss             | 0.000 |
|    need_loss            | 149.588 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1433600 |
| Episodes                | 17609 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 128.1264 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 12338 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2831.428 |
|    value_loss_int       | 9.436 |
|    entropy_loss         | 0.955 |
|    rnd_loss             | 0.000 |
|    need_loss            | 155.169 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1437696 |
| Episodes                | 17672 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 75.0420 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 12374 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.005 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3157.140 |
|    value_loss_int       | 9.232 |
|    entropy_loss         | 0.885 |
|    rnd_loss             | 0.000 |
|    need_loss            | 149.315 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1441792 |
| Episodes                | 17737 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.3887 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 12409 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2757.603 |
|    value_loss_int       | 8.729 |
|    entropy_loss         | 0.862 |
|    rnd_loss             | 0.000 |
|    need_loss            | 142.904 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.778 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1445888 |
| Episodes                | 17801 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 146.6308 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 12444 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3283.654 |
|    value_loss_int       | 8.540 |
|    entropy_loss         | 0.868 |
|    rnd_loss             | 0.000 |
|    need_loss            | 139.603 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.779 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1449984 |
| Episodes                | 17867 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 51.5189 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 12480 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2648.863 |
|    value_loss_int       | 7.694 |
|    entropy_loss         | 0.842 |
|    rnd_loss             | 0.000 |
|    need_loss            | 135.930 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1450000.pt at timestep 1450000
---------------------------------
| Timestep                | 1454080 |
| Episodes                | 17932 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 156.3551 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.1 |
|    time_elapsed         | 12516 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3339.341 |
|    value_loss_int       | 7.964 |
|    entropy_loss         | 0.805 |
|    rnd_loss             | 0.000 |
|    need_loss            | 132.064 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1458176 |
| Episodes                | 17998 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 195.0929 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 12551 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3006.840 |
|    value_loss_int       | 8.093 |
|    entropy_loss         | 0.836 |
|    rnd_loss             | 0.000 |
|    need_loss            | 131.155 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1462272 |
| Episodes                | 18062 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 100.3167 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 12586 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3409.002 |
|    value_loss_int       | 8.435 |
|    entropy_loss         | 0.837 |
|    rnd_loss             | 0.000 |
|    need_loss            | 135.299 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1466368 |
| Episodes                | 18128 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 56.5352 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 12622 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3022.952 |
|    value_loss_int       | 7.683 |
|    entropy_loss         | 0.914 |
|    rnd_loss             | 0.000 |
|    need_loss            | 133.039 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1470464 |
| Episodes                | 18191 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 171.5641 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 12657 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3371.480 |
|    value_loss_int       | 7.679 |
|    entropy_loss         | 0.881 |
|    rnd_loss             | 0.000 |
|    need_loss            | 128.211 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1474560 |
| Episodes                | 18253 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 103.7474 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 12692 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3300.996 |
|    value_loss_int       | 8.671 |
|    entropy_loss         | 0.870 |
|    rnd_loss             | 0.000 |
|    need_loss            | 135.849 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1478656 |
| Episodes                | 18315 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 218.1147 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 12728 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3109.151 |
|    value_loss_int       | 8.805 |
|    entropy_loss         | 0.835 |
|    rnd_loss             | 0.000 |
|    need_loss            | 140.921 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1482752 |
| Episodes                | 18377 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 136.2878 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.0 |
|    time_elapsed         | 12762 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3400.944 |
|    value_loss_int       | 9.124 |
|    entropy_loss         | 0.863 |
|    rnd_loss             | 0.000 |
|    need_loss            | 141.155 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.780 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1486848 |
| Episodes                | 18442 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 139.0336 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 12797 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3089.558 |
|    value_loss_int       | 8.895 |
|    entropy_loss         | 0.926 |
|    rnd_loss             | 0.000 |
|    need_loss            | 135.646 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1490944 |
| Episodes                | 18503 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 229.8540 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.6 |
|    time_elapsed         | 12831 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.013 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3068.840 |
|    value_loss_int       | 8.634 |
|    entropy_loss         | 0.907 |
|    rnd_loss             | 0.000 |
|    need_loss            | 138.148 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1495040 |
| Episodes                | 18566 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 193.0436 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 12865 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3048.931 |
|    value_loss_int       | 8.542 |
|    entropy_loss         | 0.898 |
|    rnd_loss             | 0.000 |
|    need_loss            | 138.724 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1499136 |
| Episodes                | 18631 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 115.0580 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 12899 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3043.689 |
|    value_loss_int       | 8.361 |
|    entropy_loss         | 0.817 |
|    rnd_loss             | 0.000 |
|    need_loss            | 137.040 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1500000.pt at timestep 1500000
---------------------------------
| Timestep                | 1503232 |
| Episodes                | 18697 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 169.8235 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.9 |
|    time_elapsed         | 12934 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3139.768 |
|    value_loss_int       | 7.896 |
|    entropy_loss         | 0.866 |
|    rnd_loss             | 0.000 |
|    need_loss            | 132.873 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1507328 |
| Episodes                | 18759 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 75.4506 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 12968 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3159.155 |
|    value_loss_int       | 7.863 |
|    entropy_loss         | 0.847 |
|    rnd_loss             | 0.000 |
|    need_loss            | 133.410 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.782 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1511424 |
| Episodes                | 18822 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 134.1501 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 13002 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3194.694 |
|    value_loss_int       | 8.095 |
|    entropy_loss         | 0.810 |
|    rnd_loss             | 0.000 |
|    need_loss            | 135.775 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.781 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1515520 |
| Episodes                | 18883 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 173.1176 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 13037 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3937.729 |
|    value_loss_int       | 8.630 |
|    entropy_loss         | 0.749 |
|    rnd_loss             | 0.000 |
|    need_loss            | 138.070 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.783 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1519616 |
| Episodes                | 18948 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 119.6592 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.7 |
|    time_elapsed         | 13072 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3637.338 |
|    value_loss_int       | 8.503 |
|    entropy_loss         | 0.696 |
|    rnd_loss             | 0.000 |
|    need_loss            | 136.393 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1523712 |
| Episodes                | 19012 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 253.3706 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 13107 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3952.144 |
|    value_loss_int       | 8.631 |
|    entropy_loss         | 0.742 |
|    rnd_loss             | 0.000 |
|    need_loss            | 136.809 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1527808 |
| Episodes                | 19073 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 199.7768 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 13143 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3841.628 |
|    value_loss_int       | 8.508 |
|    entropy_loss         | 0.703 |
|    rnd_loss             | 0.000 |
|    need_loss            | 136.765 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1531904 |
| Episodes                | 19141 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 197.7032 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 13178 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3362.932 |
|    value_loss_int       | 8.007 |
|    entropy_loss         | 0.644 |
|    rnd_loss             | 0.000 |
|    need_loss            | 133.552 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1536000 |
| Episodes                | 19207 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 166.5356 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 13213 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3361.940 |
|    value_loss_int       | 7.580 |
|    entropy_loss         | 0.651 |
|    rnd_loss             | 0.000 |
|    need_loss            | 127.408 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1540096 |
| Episodes                | 19276 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 134.2128 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 13248 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3252.566 |
|    value_loss_int       | 6.849 |
|    entropy_loss         | 0.759 |
|    rnd_loss             | 0.000 |
|    need_loss            | 123.462 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1544192 |
| Episodes                | 19337 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 103.7087 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 13284 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3851.120 |
|    value_loss_int       | 7.240 |
|    entropy_loss         | 0.691 |
|    rnd_loss             | 0.000 |
|    need_loss            | 120.168 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1548288 |
| Episodes                | 19401 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 155.7383 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.6 |
|    time_elapsed         | 13319 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3601.421 |
|    value_loss_int       | 7.472 |
|    entropy_loss         | 0.720 |
|    rnd_loss             | 0.000 |
|    need_loss            | 124.035 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1550000.pt at timestep 1550000
---------------------------------
| Timestep                | 1552384 |
| Episodes                | 19470 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 187.0370 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.8 |
|    time_elapsed         | 13355 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3226.908 |
|    value_loss_int       | 7.205 |
|    entropy_loss         | 0.729 |
|    rnd_loss             | 0.000 |
|    need_loss            | 123.462 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1556480 |
| Episodes                | 19535 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 119.4325 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 13391 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3472.152 |
|    value_loss_int       | 7.274 |
|    entropy_loss         | 0.708 |
|    rnd_loss             | 0.000 |
|    need_loss            | 124.290 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1560576 |
| Episodes                | 19597 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 137.4140 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.5 |
|    time_elapsed         | 13426 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.002 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4162.618 |
|    value_loss_int       | 7.694 |
|    entropy_loss         | 0.700 |
|    rnd_loss             | 0.000 |
|    need_loss            | 125.864 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.784 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1564672 |
| Episodes                | 19665 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 116.3283 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 13461 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3305.095 |
|    value_loss_int       | 7.148 |
|    entropy_loss         | 0.777 |
|    rnd_loss             | 0.000 |
|    need_loss            | 122.764 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1568768 |
| Episodes                | 19731 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 79.1292 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 13497 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3537.866 |
|    value_loss_int       | 7.356 |
|    entropy_loss         | 0.790 |
|    rnd_loss             | 0.000 |
|    need_loss            | 119.135 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1572864 |
| Episodes                | 19792 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 115.8932 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 13532 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3506.866 |
|    value_loss_int       | 7.661 |
|    entropy_loss         | 0.711 |
|    rnd_loss             | 0.000 |
|    need_loss            | 123.029 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1576960 |
| Episodes                | 19856 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 160.1377 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.4 |
|    time_elapsed         | 13567 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 4044.309 |
|    value_loss_int       | 8.123 |
|    entropy_loss         | 0.745 |
|    rnd_loss             | 0.000 |
|    need_loss            | 127.205 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1581056 |
| Episodes                | 19921 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 187.4408 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 13603 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3386.865 |
|    value_loss_int       | 7.641 |
|    entropy_loss         | 0.781 |
|    rnd_loss             | 0.000 |
|    need_loss            | 126.946 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1585152 |
| Episodes                | 19984 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 135.2564 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 13638 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3045.624 |
|    value_loss_int       | 7.565 |
|    entropy_loss         | 0.812 |
|    rnd_loss             | 0.000 |
|    need_loss            | 127.285 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1589248 |
| Episodes                | 20048 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 172.9956 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 13672 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2975.541 |
|    value_loss_int       | 7.452 |
|    entropy_loss         | 0.914 |
|    rnd_loss             | 0.000 |
|    need_loss            | 122.468 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.785 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1593344 |
| Episodes                | 20110 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 189.0454 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 13707 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3547.611 |
|    value_loss_int       | 7.752 |
|    entropy_loss         | 0.829 |
|    rnd_loss             | 0.000 |
|    need_loss            | 125.280 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1597440 |
| Episodes                | 20178 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 231.8271 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 13741 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2976.242 |
|    value_loss_int       | 7.318 |
|    entropy_loss         | 0.892 |
|    rnd_loss             | 0.000 |
|    need_loss            | 125.582 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.786 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1600000.pt at timestep 1600000
---------------------------------
| Timestep                | 1601536 |
| Episodes                | 20242 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 117.0444 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.6 |
|    time_elapsed         | 13776 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3348.977 |
|    value_loss_int       | 7.045 |
|    entropy_loss         | 0.811 |
|    rnd_loss             | 0.000 |
|    need_loss            | 119.774 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.787 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1605632 |
| Episodes                | 20308 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 153.9082 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 13810 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3435.637 |
|    value_loss_int       | 7.013 |
|    entropy_loss         | 0.815 |
|    rnd_loss             | 0.000 |
|    need_loss            | 119.054 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.788 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1609728 |
| Episodes                | 20374 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 168.9592 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 13844 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3147.631 |
|    value_loss_int       | 6.632 |
|    entropy_loss         | 0.843 |
|    rnd_loss             | 0.000 |
|    need_loss            | 114.938 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.788 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1613824 |
| Episodes                | 20440 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 145.1567 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 13878 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 3274.767 |
|    value_loss_int       | 7.054 |
|    entropy_loss         | 0.785 |
|    rnd_loss             | 0.000 |
|    need_loss            | 113.853 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.789 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1617920 |
| Episodes                | 20504 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 216.2304 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 13912 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3338.400 |
|    value_loss_int       | 6.754 |
|    entropy_loss         | 0.821 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.440 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.790 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1622016 |
| Episodes                | 20567 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 85.4697 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.3 |
|    time_elapsed         | 13947 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3290.775 |
|    value_loss_int       | 7.273 |
|    entropy_loss         | 0.840 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.856 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.790 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1626112 |
| Episodes                | 20630 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 126.5311 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 13983 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3313.921 |
|    value_loss_int       | 7.491 |
|    entropy_loss         | 0.850 |
|    rnd_loss             | 0.000 |
|    need_loss            | 122.213 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1630208 |
| Episodes                | 20689 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 135.3530 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 14018 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3415.424 |
|    value_loss_int       | 7.399 |
|    entropy_loss         | 0.888 |
|    rnd_loss             | 0.000 |
|    need_loss            | 123.449 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1634304 |
| Episodes                | 20754 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 128.0264 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 14054 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2896.880 |
|    value_loss_int       | 7.650 |
|    entropy_loss         | 0.916 |
|    rnd_loss             | 0.000 |
|    need_loss            | 127.121 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1638400 |
| Episodes                | 20817 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 79.1962 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 14089 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2825.278 |
|    value_loss_int       | 7.474 |
|    entropy_loss         | 1.004 |
|    rnd_loss             | 0.000 |
|    need_loss            | 122.036 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1642496 |
| Episodes                | 20882 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 78.9708 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 14125 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2635.133 |
|    value_loss_int       | 6.867 |
|    entropy_loss         | 0.913 |
|    rnd_loss             | 0.000 |
|    need_loss            | 119.136 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1646592 |
| Episodes                | 20945 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 220.8801 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 14160 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3208.926 |
|    value_loss_int       | 7.074 |
|    entropy_loss         | 0.876 |
|    rnd_loss             | 0.000 |
|    need_loss            | 117.087 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1650000.pt at timestep 1650000
---------------------------------
| Timestep                | 1650688 |
| Episodes                | 21009 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 85.3885 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.5 |
|    time_elapsed         | 14196 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2532.616 |
|    value_loss_int       | 6.968 |
|    entropy_loss         | 0.970 |
|    rnd_loss             | 0.000 |
|    need_loss            | 115.976 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1654784 |
| Episodes                | 21073 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 81.8853 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 14232 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2869.013 |
|    value_loss_int       | 6.778 |
|    entropy_loss         | 0.925 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.372 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1658880 |
| Episodes                | 21139 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 90.6170 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.5 |
|    time_elapsed         | 14267 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2547.009 |
|    value_loss_int       | 6.846 |
|    entropy_loss         | 0.955 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.456 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1662976 |
| Episodes                | 21205 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 71.7032 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 14303 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2700.725 |
|    value_loss_int       | 6.985 |
|    entropy_loss         | 0.979 |
|    rnd_loss             | 0.000 |
|    need_loss            | 116.003 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1667072 |
| Episodes                | 21270 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 140.3910 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 14338 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2432.098 |
|    value_loss_int       | 6.497 |
|    entropy_loss         | 1.024 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.978 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1671168 |
| Episodes                | 21333 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 106.9094 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 14374 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2575.581 |
|    value_loss_int       | 6.890 |
|    entropy_loss         | 1.045 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.401 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1675264 |
| Episodes                | 21398 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 149.3203 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 14409 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2449.140 |
|    value_loss_int       | 6.573 |
|    entropy_loss         | 1.044 |
|    rnd_loss             | 0.000 |
|    need_loss            | 109.216 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1679360 |
| Episodes                | 21456 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.1406 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 14445 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3165.963 |
|    value_loss_int       | 7.008 |
|    entropy_loss         | 0.943 |
|    rnd_loss             | 0.000 |
|    need_loss            | 114.756 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1683456 |
| Episodes                | 21520 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 143.1052 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.0 |
|    time_elapsed         | 14480 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2869.343 |
|    value_loss_int       | 7.508 |
|    entropy_loss         | 0.973 |
|    rnd_loss             | 0.000 |
|    need_loss            | 120.484 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1687552 |
| Episodes                | 21582 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 171.6102 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.8 |
|    time_elapsed         | 14516 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2748.494 |
|    value_loss_int       | 7.101 |
|    entropy_loss         | 0.930 |
|    rnd_loss             | 0.000 |
|    need_loss            | 118.697 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1691648 |
| Episodes                | 21648 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 175.8276 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.7 |
|    time_elapsed         | 14551 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2665.616 |
|    value_loss_int       | 7.233 |
|    entropy_loss         | 1.002 |
|    rnd_loss             | 0.000 |
|    need_loss            | 117.893 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1695744 |
| Episodes                | 21714 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 73.1849 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 14587 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2546.144 |
|    value_loss_int       | 6.548 |
|    entropy_loss         | 1.044 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.917 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1699840 |
| Episodes                | 21779 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 55.9010 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 14622 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2347.351 |
|    value_loss_int       | 6.293 |
|    entropy_loss         | 0.975 |
|    rnd_loss             | 0.000 |
|    need_loss            | 110.422 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1700000.pt at timestep 1700000
---------------------------------
| Timestep                | 1703936 |
| Episodes                | 21844 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 52.3463 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.9 |
|    time_elapsed         | 14658 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2499.204 |
|    value_loss_int       | 6.417 |
|    entropy_loss         | 0.972 |
|    rnd_loss             | 0.000 |
|    need_loss            | 111.906 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1708032 |
| Episodes                | 21910 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 186.6152 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.3 |
|    time_elapsed         | 14693 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2978.338 |
|    value_loss_int       | 6.861 |
|    entropy_loss         | 0.995 |
|    rnd_loss             | 0.000 |
|    need_loss            | 110.841 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.791 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1712128 |
| Episodes                | 21973 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 98.2517 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 14729 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.030 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2592.478 |
|    value_loss_int       | 6.456 |
|    entropy_loss         | 0.899 |
|    rnd_loss             | 0.000 |
|    need_loss            | 110.430 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1716224 |
| Episodes                | 22042 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 138.1205 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 117.0 |
|    time_elapsed         | 14764 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2828.260 |
|    value_loss_int       | 6.238 |
|    entropy_loss         | 0.908 |
|    rnd_loss             | 0.000 |
|    need_loss            | 107.253 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1720320 |
| Episodes                | 22102 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 128.7572 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 14798 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3507.826 |
|    value_loss_int       | 6.214 |
|    entropy_loss         | 0.832 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.654 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.792 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1724416 |
| Episodes                | 22163 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 123.4247 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.5 |
|    time_elapsed         | 14832 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3380.070 |
|    value_loss_int       | 6.888 |
|    entropy_loss         | 0.867 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.198 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.793 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1728512 |
| Episodes                | 22226 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 183.0470 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.1 |
|    time_elapsed         | 14867 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2833.267 |
|    value_loss_int       | 6.644 |
|    entropy_loss         | 0.794 |
|    rnd_loss             | 0.000 |
|    need_loss            | 113.819 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.794 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1732608 |
| Episodes                | 22292 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 85.0236 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 14901 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3216.867 |
|    value_loss_int       | 6.798 |
|    entropy_loss         | 0.849 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.938 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.795 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1736704 |
| Episodes                | 22354 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 132.7476 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.2 |
|    time_elapsed         | 14935 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3234.309 |
|    value_loss_int       | 6.726 |
|    entropy_loss         | 0.880 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.545 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1740800 |
| Episodes                | 22417 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 110.9048 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.3 |
|    time_elapsed         | 14969 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3206.006 |
|    value_loss_int       | 6.564 |
|    entropy_loss         | 0.871 |
|    rnd_loss             | 0.000 |
|    need_loss            | 111.026 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1744896 |
| Episodes                | 22480 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 111.2627 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.4 |
|    time_elapsed         | 15003 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 3001.195 |
|    value_loss_int       | 6.365 |
|    entropy_loss         | 0.923 |
|    rnd_loss             | 0.000 |
|    need_loss            | 109.393 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1748992 |
| Episodes                | 22545 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 123.3004 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 120.0 |
|    time_elapsed         | 15038 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3014.836 |
|    value_loss_int       | 7.064 |
|    entropy_loss         | 0.906 |
|    rnd_loss             | 0.000 |
|    need_loss            | 112.089 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1750000.pt at timestep 1750000
---------------------------------
| Timestep                | 1753088 |
| Episodes                | 22614 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 134.0647 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.1 |
|    time_elapsed         | 15073 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2554.631 |
|    value_loss_int       | 6.577 |
|    entropy_loss         | 0.917 |
|    rnd_loss             | 0.000 |
|    need_loss            | 107.630 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1757184 |
| Episodes                | 22681 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 171.4564 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.1 |
|    time_elapsed         | 15109 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2721.247 |
|    value_loss_int       | 5.781 |
|    entropy_loss         | 0.956 |
|    rnd_loss             | 0.000 |
|    need_loss            | 102.757 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1761280 |
| Episodes                | 22744 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 114.7191 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 116.2 |
|    time_elapsed         | 15144 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2966.515 |
|    value_loss_int       | 5.993 |
|    entropy_loss         | 0.918 |
|    rnd_loss             | 0.000 |
|    need_loss            | 100.482 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1765376 |
| Episodes                | 22812 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 92.2685 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 112.8 |
|    time_elapsed         | 15180 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2697.590 |
|    value_loss_int       | 6.121 |
|    entropy_loss         | 0.976 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.033 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1769472 |
| Episodes                | 22876 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 128.8945 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.2 |
|    time_elapsed         | 15216 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2978.963 |
|    value_loss_int       | 6.009 |
|    entropy_loss         | 0.900 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.510 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1773568 |
| Episodes                | 22938 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 147.4717 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.8 |
|    time_elapsed         | 15252 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2939.219 |
|    value_loss_int       | 6.030 |
|    entropy_loss         | 0.915 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.367 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1777664 |
| Episodes                | 23005 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 60.7690 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.5 |
|    time_elapsed         | 15288 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2797.226 |
|    value_loss_int       | 6.352 |
|    entropy_loss         | 0.921 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.618 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1781760 |
| Episodes                | 23071 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 81.5987 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 15324 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2694.047 |
|    value_loss_int       | 6.117 |
|    entropy_loss         | 0.889 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.777 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1785856 |
| Episodes                | 23134 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 133.5301 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 15360 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2983.386 |
|    value_loss_int       | 6.352 |
|    entropy_loss         | 0.874 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.087 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1789952 |
| Episodes                | 23202 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 88.4393 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.1 |
|    time_elapsed         | 15396 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2687.180 |
|    value_loss_int       | 6.446 |
|    entropy_loss         | 0.876 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.091 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1794048 |
| Episodes                | 23268 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 81.7330 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 15432 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2810.245 |
|    value_loss_int       | 5.798 |
|    entropy_loss         | 0.861 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.743 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.796 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1798144 |
| Episodes                | 23335 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 45.8678 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 15467 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2776.644 |
|    value_loss_int       | 5.630 |
|    entropy_loss         | 0.909 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.041 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1800000.pt at timestep 1800000
---------------------------------
| Timestep                | 1802240 |
| Episodes                | 23401 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 95.6645 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 105.4 |
|    time_elapsed         | 15506 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2889.065 |
|    value_loss_int       | 5.678 |
|    entropy_loss         | 0.850 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.201 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1806336 |
| Episodes                | 23465 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 127.3746 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 15542 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2723.101 |
|    value_loss_int       | 5.643 |
|    entropy_loss         | 0.927 |
|    rnd_loss             | 0.000 |
|    need_loss            | 100.782 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1810432 |
| Episodes                | 23534 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 89.8981 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 108.8 |
|    time_elapsed         | 15580 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2609.844 |
|    value_loss_int       | 5.198 |
|    entropy_loss         | 0.896 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.579 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1814528 |
| Episodes                | 23599 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 139.4751 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 107.5 |
|    time_elapsed         | 15618 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2578.040 |
|    value_loss_int       | 5.318 |
|    entropy_loss         | 0.917 |
|    rnd_loss             | 0.000 |
|    need_loss            | 97.492 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1818624 |
| Episodes                | 23666 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 118.6984 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 110.4 |
|    time_elapsed         | 15655 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2635.007 |
|    value_loss_int       | 5.379 |
|    entropy_loss         | 0.895 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.411 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1822720 |
| Episodes                | 23725 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 145.3779 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.4 |
|    time_elapsed         | 15691 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 3348.085 |
|    value_loss_int       | 6.304 |
|    entropy_loss         | 0.873 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.894 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1826816 |
| Episodes                | 23788 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 143.7143 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.2 |
|    time_elapsed         | 15727 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2947.055 |
|    value_loss_int       | 6.203 |
|    entropy_loss         | 0.872 |
|    rnd_loss             | 0.000 |
|    need_loss            | 107.032 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1830912 |
| Episodes                | 23851 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 66.5313 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.3 |
|    time_elapsed         | 15763 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2859.881 |
|    value_loss_int       | 6.249 |
|    entropy_loss         | 0.920 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.616 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1835008 |
| Episodes                | 23916 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 151.5710 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.0 |
|    time_elapsed         | 15799 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3197.783 |
|    value_loss_int       | 6.768 |
|    entropy_loss         | 0.869 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.672 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1839104 |
| Episodes                | 23982 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 116.2174 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.3 |
|    time_elapsed         | 15834 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2552.249 |
|    value_loss_int       | 6.296 |
|    entropy_loss         | 0.924 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.753 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1843200 |
| Episodes                | 24048 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 87.5539 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.2 |
|    time_elapsed         | 15870 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2524.974 |
|    value_loss_int       | 5.640 |
|    entropy_loss         | 0.969 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.818 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.797 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1847296 |
| Episodes                | 24116 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 89.5073 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 111.0 |
|    time_elapsed         | 15907 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2704.432 |
|    value_loss_int       | 5.494 |
|    entropy_loss         | 0.956 |
|    rnd_loss             | 0.000 |
|    need_loss            | 97.888 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1850000.pt at timestep 1850000
---------------------------------
| Timestep                | 1851392 |
| Episodes                | 24183 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 159.0023 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 87.2  |
|    time_elapsed         | 15954 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2985.595 |
|    value_loss_int       | 5.408 |
|    entropy_loss         | 0.894 |
|    rnd_loss             | 0.000 |
|    need_loss            | 93.773 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1855488 |
| Episodes                | 24244 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 108.4106 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.7 |
|    time_elapsed         | 15990 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3266.765 |
|    value_loss_int       | 5.682 |
|    entropy_loss         | 0.906 |
|    rnd_loss             | 0.000 |
|    need_loss            | 94.971 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1859584 |
| Episodes                | 24310 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 111.9496 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 92.2  |
|    time_elapsed         | 16035 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2765.838 |
|    value_loss_int       | 6.605 |
|    entropy_loss         | 0.959 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.178 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.799 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1863680 |
| Episodes                | 24375 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 151.0610 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.0 |
|    time_elapsed         | 16070 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2570.214 |
|    value_loss_int       | 6.022 |
|    entropy_loss         | 1.030 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.923 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.798 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1867776 |
| Episodes                | 24441 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 97.5738 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.7 |
|    time_elapsed         | 16105 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2701.911 |
|    value_loss_int       | 6.078 |
|    entropy_loss         | 1.135 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.911 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.801 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1871872 |
| Episodes                | 24500 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 183.3695 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 118.8 |
|    time_elapsed         | 16140 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2634.158 |
|    value_loss_int       | 5.796 |
|    entropy_loss         | 1.087 |
|    rnd_loss             | 0.000 |
|    need_loss            | 100.028 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.802 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1875968 |
| Episodes                | 24558 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 73.2929 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.9 |
|    time_elapsed         | 16175 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2278.144 |
|    value_loss_int       | 6.003 |
|    entropy_loss         | 1.074 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.261 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.802 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1880064 |
| Episodes                | 24620 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 90.6967 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 95.0  |
|    time_elapsed         | 16218 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2141.903 |
|    value_loss_int       | 6.151 |
|    entropy_loss         | 1.081 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.296 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.802 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1884160 |
| Episodes                | 24680 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 237.2589 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 111.7 |
|    time_elapsed         | 16255 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2877.326 |
|    value_loss_int       | 6.640 |
|    entropy_loss         | 1.029 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.180 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.803 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1888256 |
| Episodes                | 24742 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 111.8790 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 96.5  |
|    time_elapsed         | 16298 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2664.204 |
|    value_loss_int       | 6.126 |
|    entropy_loss         | 1.005 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.614 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.802 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1892352 |
| Episodes                | 24807 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 114.8798 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 104.1 |
|    time_elapsed         | 16337 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2559.570 |
|    value_loss_int       | 6.406 |
|    entropy_loss         | 1.086 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.973 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.801 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1896448 |
| Episodes                | 24868 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 106.8826 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 105.3 |
|    time_elapsed         | 16376 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2576.795 |
|    value_loss_int       | 6.228 |
|    entropy_loss         | 1.125 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.770 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.805 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1900000.pt at timestep 1900000
---------------------------------
| Timestep                | 1900544 |
| Episodes                | 24934 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 58.8494 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 99.7  |
|    time_elapsed         | 16418 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2099.394 |
|    value_loss_int       | 5.955 |
|    entropy_loss         | 1.190 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.675 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.805 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1904640 |
| Episodes                | 24994 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 60.3117 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.0 |
|    time_elapsed         | 16453 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2586.830 |
|    value_loss_int       | 6.201 |
|    entropy_loss         | 1.117 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.281 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.804 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1908736 |
| Episodes                | 25054 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 66.2924 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 89.3  |
|    time_elapsed         | 16499 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2547.481 |
|    value_loss_int       | 6.154 |
|    entropy_loss         | 1.178 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.403 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.806 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1912832 |
| Episodes                | 25117 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 109.1097 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 109.4 |
|    time_elapsed         | 16537 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2617.782 |
|    value_loss_int       | 6.578 |
|    entropy_loss         | 1.173 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.244 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1916928 |
| Episodes                | 25176 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 129.9454 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 112.1 |
|    time_elapsed         | 16574 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.020 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2269.578 |
|    value_loss_int       | 6.197 |
|    entropy_loss         | 1.142 |
|    rnd_loss             | 0.000 |
|    need_loss            | 104.909 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1921024 |
| Episodes                | 25236 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 104.0439 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 16609 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2516.633 |
|    value_loss_int       | 6.200 |
|    entropy_loss         | 1.087 |
|    rnd_loss             | 0.000 |
|    need_loss            | 103.410 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.806 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1925120 |
| Episodes                | 25299 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 44.8181 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 89.0  |
|    time_elapsed         | 16656 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2102.131 |
|    value_loss_int       | 6.145 |
|    entropy_loss         | 1.049 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.439 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.806 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1929216 |
| Episodes                | 25358 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 103.7746 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 106.2 |
|    time_elapsed         | 16694 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2839.733 |
|    value_loss_int       | 6.251 |
|    entropy_loss         | 1.023 |
|    rnd_loss             | 0.000 |
|    need_loss            | 106.184 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1933312 |
| Episodes                | 25419 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 142.1630 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.6 |
|    time_elapsed         | 16730 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2501.695 |
|    value_loss_int       | 6.361 |
|    entropy_loss         | 1.087 |
|    rnd_loss             | 0.000 |
|    need_loss            | 107.157 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1937408 |
| Episodes                | 25483 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 29.2432 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 115.1 |
|    time_elapsed         | 16766 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2287.091 |
|    value_loss_int       | 6.280 |
|    entropy_loss         | 1.119 |
|    rnd_loss             | 0.000 |
|    need_loss            | 105.537 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1941504 |
| Episodes                | 25548 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 112.7796 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.3 |
|    time_elapsed         | 16801 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2319.071 |
|    value_loss_int       | 6.436 |
|    entropy_loss         | 1.222 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.277 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1945600 |
| Episodes                | 25609 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 122.6662 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.3 |
|    time_elapsed         | 16837 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.029 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2325.567 |
|    value_loss_int       | 6.047 |
|    entropy_loss         | 1.109 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.934 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1949696 |
| Episodes                | 25668 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 90.7943 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 113.1 |
|    time_elapsed         | 16874 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.010 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2664.925 |
|    value_loss_int       | 6.001 |
|    entropy_loss         | 1.025 |
|    rnd_loss             | 0.000 |
|    need_loss            | 102.806 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts1950000.pt at timestep 1950000
---------------------------------
| Timestep                | 1953792 |
| Episodes                | 25734 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 79.0259 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 76.3  |
|    time_elapsed         | 16928 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.037 |
|    policy_loss          | -0.002 |
|    value_loss_ext       | 2017.870 |
|    value_loss_int       | 5.699 |
|    entropy_loss         | 0.993 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.980 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1957888 |
| Episodes                | 25796 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 150.0073 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.8 |
|    time_elapsed         | 16963 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.004 |
|    policy_loss          | 0.001 |
|    value_loss_ext       | 2808.458 |
|    value_loss_int       | 5.987 |
|    entropy_loss         | 0.998 |
|    rnd_loss             | 0.000 |
|    need_loss            | 100.482 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1961984 |
| Episodes                | 25860 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 117.6438 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.9 |
|    time_elapsed         | 16999 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    policy_loss          | -0.001 |
|    value_loss_ext       | 2348.422 |
|    value_loss_int       | 6.236 |
|    entropy_loss         | 1.021 |
|    rnd_loss             | 0.000 |
|    need_loss            | 101.100 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1966080 |
| Episodes                | 25920 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 89.0560 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 114.3 |
|    time_elapsed         | 17035 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.003 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2585.952 |
|    value_loss_int       | 5.845 |
|    entropy_loss         | 1.029 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.710 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1970176 |
| Episodes                | 25986 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 128.3930 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 103.9 |
|    time_elapsed         | 17075 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.013 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2412.120 |
|    value_loss_int       | 5.619 |
|    entropy_loss         | 1.087 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.632 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1974272 |
| Episodes                | 26048 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 83.2582 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 94.4  |
|    time_elapsed         | 17118 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2439.511 |
|    value_loss_int       | 5.809 |
|    entropy_loss         | 1.079 |
|    rnd_loss             | 0.000 |
|    need_loss            | 98.168 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1978368 |
| Episodes                | 26112 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 69.4983 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 98.1  |
|    time_elapsed         | 17160 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.006 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2659.078 |
|    value_loss_int       | 5.941 |
|    entropy_loss         | 1.073 |
|    rnd_loss             | 0.000 |
|    need_loss            | 99.711 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1982464 |
| Episodes                | 26179 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 104.0376 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 103.7 |
|    time_elapsed         | 17200 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2185.830 |
|    value_loss_int       | 5.216 |
|    entropy_loss         | 1.101 |
|    rnd_loss             | 0.000 |
|    need_loss            | 95.041 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1986560 |
| Episodes                | 26247 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 17.8112 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 82.4  |
|    time_elapsed         | 17250 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.014 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2570.540 |
|    value_loss_int       | 5.315 |
|    entropy_loss         | 0.984 |
|    rnd_loss             | 0.000 |
|    need_loss            | 91.757 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1990656 |
| Episodes                | 26307 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 152.7086 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 95.1  |
|    time_elapsed         | 17293 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.002 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 3207.920 |
|    value_loss_int       | 5.262 |
|    entropy_loss         | 0.836 |
|    rnd_loss             | 0.000 |
|    need_loss            | 90.874 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1994752 |
| Episodes                | 26373 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 127.3698 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 104.8 |
|    time_elapsed         | 17332 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2979.006 |
|    value_loss_int       | 5.672 |
|    entropy_loss         | 0.924 |
|    rnd_loss             | 0.000 |
|    need_loss            | 94.720 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.808 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
---------------------------------
| Timestep                | 1998848 |
| Episodes                | 26439 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 89.3208 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 103.8 |
|    time_elapsed         | 17372 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    policy_loss          | -0.000 |
|    value_loss_ext       | 2601.054 |
|    value_loss_int       | 5.050 |
|    entropy_loss         | 0.917 |
|    rnd_loss             | 0.000 |
|    need_loss            | 91.680 |
|    explained_variance   | 0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Checkpoint saved to models/VizdoomCorridor_ppo_infini_ivrl_ts2000000.pt at timestep 2000000
---------------------------------
| Timestep                | 2000000 |
| Episodes                | 26458 |
| rollout/                |       |
|    ep_rew_mean (ext)    | 66.4423 |
|    best_mean_reward     | 313.121 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 269.8 |
|    time_elapsed         | 17387 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    policy_loss          | 0.000 |
|    value_loss_ext       | 2603.126 |
|    value_loss_int       | 6.036 |
|    entropy_loss         | 0.962 |
|    rnd_loss             | 0.000 |
|    need_loss            | 91.241 |
|    explained_variance   | -0.000 |
|    beta (learned)       | 0.807 |
|    learning_rate        | 0.00025 |
|    rnd_learning_rate    | 0.00010 |
|    need_learning_rate   | 0.00010 |
---------------------------------
Training completed!
============================== Final Statistics ==============================
Total episodes completed: 26458
Final average episode reward (last 10): 66.442
Best mean reward achieved: 313.121
Total timesteps: 2000000
Total training time: 17387.4s
Best model saved to: models/VizdoomCorridor_ppo_infini_ivrl_best.pt
