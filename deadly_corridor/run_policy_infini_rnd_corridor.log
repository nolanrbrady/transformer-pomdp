/home/nbrady/.conda/envs/vizdoom/lib/python3.11/site-packages/vizdoom/gymnasium_wrapper/base_gymnasium_env.py:84: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gymnasium wrapper. Forcing RGB24.
  warnings.warn(
Using device: cuda
Environment created: VizdoomCorridor-v0
Observation space: Dict('gamevariables': Box(-3.4028235e+38, 3.4028235e+38, (1,), float32), 'screen': Box(0, 255, (240, 320, 3), uint8))
Action space: Discrete(8)
Using grid of 6x6 patches = 36 total patches
InfiniViT model initialized on: cuda
Models initialized on device
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 74.4  |
|    ep_rew_mean          | -106.829 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 131.9 |
|    iteration            | 1     |
|    time_elapsed         | 31    |
|    total_timesteps      | 4096  |
|-------------------------|-------|
New best model! Mean reward: -106.829. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.179 |
|    clip_fraction        | 0.459 |
|    entropy_loss         | 1.738 |
|    explained_variance   | -0.001 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.057 |
|    value_loss           | 620.106 |
|    rnd_loss             | 0.023 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 91.9  |
|    ep_rew_mean          | -104.278 |
|    best_mean_reward     | -106.829 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 2     |
|    time_elapsed         | 65    |
|    total_timesteps      | 8192  |
|-------------------------|-------|
New best model! Mean reward: -104.278. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.017 |
|    clip_fraction        | 0.230 |
|    entropy_loss         | 1.819 |
|    explained_variance   | 0.036 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.008 |
|    value_loss           | 455.606 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 99.9  |
|    ep_rew_mean          | -101.239 |
|    best_mean_reward     | -104.278 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 3     |
|    time_elapsed         | 99    |
|    total_timesteps      | 12288 |
|-------------------------|-------|
New best model! Mean reward: -101.239. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.154 |
|    entropy_loss         | 1.796 |
|    explained_variance   | 0.037 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.003 |
|    value_loss           | 345.745 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 100.7 |
|    ep_rew_mean          | -91.329 |
|    best_mean_reward     | -101.239 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 4     |
|    time_elapsed         | 132   |
|    total_timesteps      | 16384 |
|-------------------------|-------|
New best model! Mean reward: -91.329. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.015 |
|    clip_fraction        | 0.165 |
|    entropy_loss         | 1.707 |
|    explained_variance   | 0.057 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.003 |
|    value_loss           | 286.197 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 114.7 |
|    ep_rew_mean          | -69.291 |
|    best_mean_reward     | -91.329 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 5     |
|    time_elapsed         | 166   |
|    total_timesteps      | 20480 |
|-------------------------|-------|
New best model! Mean reward: -69.291. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.138 |
|    entropy_loss         | 1.557 |
|    explained_variance   | 0.047 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 281.647 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 107.8 |
|    ep_rew_mean          | -76.058 |
|    best_mean_reward     | -69.291 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 6     |
|    time_elapsed         | 200   |
|    total_timesteps      | 24576 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.138 |
|    entropy_loss         | 1.632 |
|    explained_variance   | 0.041 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.003 |
|    value_loss           | 282.291 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 86.6  |
|    ep_rew_mean          | -83.798 |
|    best_mean_reward     | -69.291 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 7     |
|    time_elapsed         | 233   |
|    total_timesteps      | 28672 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.081 |
|    entropy_loss         | 1.667 |
|    explained_variance   | 0.049 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 290.839 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 96.8  |
|    ep_rew_mean          | -67.674 |
|    best_mean_reward     | -69.291 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 8     |
|    time_elapsed         | 266   |
|    total_timesteps      | 32768 |
|-------------------------|-------|
New best model! Mean reward: -67.674. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.010 |
|    clip_fraction        | 0.106 |
|    entropy_loss         | 1.631 |
|    explained_variance   | 0.049 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.004 |
|    value_loss           | 284.664 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.0  |
|    ep_rew_mean          | -92.961 |
|    best_mean_reward     | -67.674 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 9     |
|    time_elapsed         | 300   |
|    total_timesteps      | 36864 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.066 |
|    entropy_loss         | 1.609 |
|    explained_variance   | 0.039 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 324.888 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 89.1  |
|    ep_rew_mean          | -61.852 |
|    best_mean_reward     | -67.674 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.5 |
|    iteration            | 10    |
|    time_elapsed         | 333   |
|    total_timesteps      | 40960 |
|-------------------------|-------|
New best model! Mean reward: -61.852. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.100 |
|    entropy_loss         | 1.707 |
|    explained_variance   | 0.060 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 290.212 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 80.1  |
|    ep_rew_mean          | -74.401 |
|    best_mean_reward     | -61.852 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.4 |
|    iteration            | 11    |
|    time_elapsed         | 367   |
|    total_timesteps      | 45056 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.146 |
|    entropy_loss         | 1.792 |
|    explained_variance   | 0.072 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.005 |
|    value_loss           | 286.902 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 80.8  |
|    ep_rew_mean          | -73.039 |
|    best_mean_reward     | -61.852 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 12    |
|    time_elapsed         | 400   |
|    total_timesteps      | 49152 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.085 |
|    entropy_loss         | 1.743 |
|    explained_variance   | 0.124 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.004 |
|    value_loss           | 318.612 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 93.3  |
|    ep_rew_mean          | -47.805 |
|    best_mean_reward     | -61.852 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.2 |
|    iteration            | 13    |
|    time_elapsed         | 432   |
|    total_timesteps      | 53248 |
|-------------------------|-------|
New best model! Mean reward: -47.805. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.017 |
|    clip_fraction        | 0.169 |
|    entropy_loss         | 1.682 |
|    explained_variance   | 0.117 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.007 |
|    value_loss           | 350.839 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 78.1  |
|    ep_rew_mean          | -38.386 |
|    best_mean_reward     | -47.805 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.4 |
|    iteration            | 14    |
|    time_elapsed         | 465   |
|    total_timesteps      | 57344 |
|-------------------------|-------|
New best model! Mean reward: -38.386. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.131 |
|    entropy_loss         | 1.704 |
|    explained_variance   | 0.106 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.010 |
|    value_loss           | 451.384 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.4  |
|    ep_rew_mean          | -31.079 |
|    best_mean_reward     | -38.386 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.0 |
|    iteration            | 15    |
|    time_elapsed         | 498   |
|    total_timesteps      | 61440 |
|-------------------------|-------|
New best model! Mean reward: -31.079. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.135 |
|    entropy_loss         | 1.686 |
|    explained_variance   | 0.172 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.010 |
|    value_loss           | 484.379 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.8  |
|    ep_rew_mean          | 0.236 |
|    best_mean_reward     | -31.079 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.8 |
|    iteration            | 16    |
|    time_elapsed         | 531   |
|    total_timesteps      | 65536 |
|-------------------------|-------|
New best model! Mean reward: 0.236. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.009 |
|    clip_fraction        | 0.098 |
|    entropy_loss         | 1.566 |
|    explained_variance   | 0.204 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 515.841 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.8  |
|    ep_rew_mean          | 6.265 |
|    best_mean_reward     | 0.236 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.9 |
|    iteration            | 17    |
|    time_elapsed         | 563   |
|    total_timesteps      | 69632 |
|-------------------------|-------|
New best model! Mean reward: 6.265. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.012 |
|    clip_fraction        | 0.138 |
|    entropy_loss         | 1.396 |
|    explained_variance   | 0.211 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.007 |
|    value_loss           | 721.643 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 51.3  |
|    ep_rew_mean          | 3.992 |
|    best_mean_reward     | 6.265 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.6 |
|    iteration            | 18    |
|    time_elapsed         | 596   |
|    total_timesteps      | 73728 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.107 |
|    entropy_loss         | 1.250 |
|    explained_variance   | 0.217 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.006 |
|    value_loss           | 1027.944 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.010 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.3  |
|    ep_rew_mean          | 91.710 |
|    best_mean_reward     | 6.265 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.7 |
|    iteration            | 19    |
|    time_elapsed         | 628   |
|    total_timesteps      | 77824 |
|-------------------------|-------|
New best model! Mean reward: 91.710. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.007 |
|    clip_fraction        | 0.088 |
|    entropy_loss         | 1.157 |
|    explained_variance   | 0.167 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.004 |
|    value_loss           | 1537.758 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.168 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.5  |
|    ep_rew_mean          | 53.836 |
|    best_mean_reward     | 91.710 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.2 |
|    iteration            | 20    |
|    time_elapsed         | 661   |
|    total_timesteps      | 81920 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.049 |
|    entropy_loss         | 1.145 |
|    explained_variance   | 0.074 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 1536.719 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.7  |
|    ep_rew_mean          | 116.324 |
|    best_mean_reward     | 91.710 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.8 |
|    iteration            | 21    |
|    time_elapsed         | 694   |
|    total_timesteps      | 86016 |
|-------------------------|-------|
New best model! Mean reward: 116.324. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.079 |
|    entropy_loss         | 1.016 |
|    explained_variance   | 0.018 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 2113.115 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 79.5  |
|    ep_rew_mean          | 194.995 |
|    best_mean_reward     | 116.324 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.8 |
|    iteration            | 22    |
|    time_elapsed         | 728   |
|    total_timesteps      | 90112 |
|-------------------------|-------|
New best model! Mean reward: 194.995. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.044 |
|    entropy_loss         | 0.981 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 2737.974 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 77.9  |
|    ep_rew_mean          | 178.948 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 23    |
|    time_elapsed         | 762   |
|    total_timesteps      | 94208 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.048 |
|    entropy_loss         | 0.904 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 2128.165 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 51.6  |
|    ep_rew_mean          | 35.275 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 24    |
|    time_elapsed         | 795   |
|    total_timesteps      | 98304 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.043 |
|    entropy_loss         | 0.818 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 3065.378 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.4  |
|    ep_rew_mean          | 130.249 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.4 |
|    iteration            | 25    |
|    time_elapsed         | 828   |
|    total_timesteps      | 102400 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.034 |
|    entropy_loss         | 0.721 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3186.879 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.9  |
|    ep_rew_mean          | 84.600 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 26    |
|    time_elapsed         | 861   |
|    total_timesteps      | 106496 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.048 |
|    entropy_loss         | 0.752 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 2638.212 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.2  |
|    ep_rew_mean          | 162.934 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.1 |
|    iteration            | 27    |
|    time_elapsed         | 893   |
|    total_timesteps      | 110592 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.731 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3164.282 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.9  |
|    ep_rew_mean          | 106.839 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.7 |
|    iteration            | 28    |
|    time_elapsed         | 925   |
|    total_timesteps      | 114688 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.040 |
|    entropy_loss         | 0.644 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3194.018 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.6  |
|    ep_rew_mean          | 124.668 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.5 |
|    iteration            | 29    |
|    time_elapsed         | 957   |
|    total_timesteps      | 118784 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.573 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3306.650 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.3  |
|    ep_rew_mean          | 96.553 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.3 |
|    iteration            | 30    |
|    time_elapsed         | 989   |
|    total_timesteps      | 122880 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.499 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3908.174 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 74.3  |
|    ep_rew_mean          | 259.257 |
|    best_mean_reward     | 194.995 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.2 |
|    iteration            | 31    |
|    time_elapsed         | 1022  |
|    total_timesteps      | 126976 |
|-------------------------|-------|
New best model! Mean reward: 259.257. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.497 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4497.270 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.7  |
|    ep_rew_mean          | 148.297 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 136.5 |
|    iteration            | 32    |
|    time_elapsed         | 1055  |
|    total_timesteps      | 131072 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.494 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4287.508 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.2  |
|    ep_rew_mean          | 154.276 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 33    |
|    time_elapsed         | 1088  |
|    total_timesteps      | 135168 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.036 |
|    entropy_loss         | 0.475 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3518.599 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.4  |
|    ep_rew_mean          | 172.142 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.5 |
|    iteration            | 34    |
|    time_elapsed         | 1122  |
|    total_timesteps      | 139264 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.430 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3944.856 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.8  |
|    ep_rew_mean          | 173.030 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 35    |
|    time_elapsed         | 1155  |
|    total_timesteps      | 143360 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.396 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3873.507 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.6  |
|    ep_rew_mean          | 222.112 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 36    |
|    time_elapsed         | 1188  |
|    total_timesteps      | 147456 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    entropy_loss         | 0.342 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4988.195 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.8  |
|    ep_rew_mean          | 122.352 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 37    |
|    time_elapsed         | 1221  |
|    total_timesteps      | 151552 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.302 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 5160.516 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.1  |
|    ep_rew_mean          | 155.451 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 38    |
|    time_elapsed         | 1254  |
|    total_timesteps      | 155648 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.320 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4262.761 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.5  |
|    ep_rew_mean          | 219.848 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 39    |
|    time_elapsed         | 1287  |
|    total_timesteps      | 159744 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.269 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4943.340 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 82.5  |
|    ep_rew_mean          | 349.046 |
|    best_mean_reward     | 259.257 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 40    |
|    time_elapsed         | 1321  |
|    total_timesteps      | 163840 |
|-------------------------|-------|
New best model! Mean reward: 349.046. Saving to models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.302 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4954.537 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.7  |
|    ep_rew_mean          | 154.398 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 41    |
|    time_elapsed         | 1355  |
|    total_timesteps      | 167936 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.317 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4862.448 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.1  |
|    ep_rew_mean          | 187.092 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 42    |
|    time_elapsed         | 1388  |
|    total_timesteps      | 172032 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.336 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4243.712 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.0  |
|    ep_rew_mean          | 150.796 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 43    |
|    time_elapsed         | 1421  |
|    total_timesteps      | 176128 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    entropy_loss         | 0.277 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 4488.420 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.9  |
|    ep_rew_mean          | 160.650 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 44    |
|    time_elapsed         | 1454  |
|    total_timesteps      | 180224 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.256 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4880.185 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.2  |
|    ep_rew_mean          | 205.672 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.5 |
|    iteration            | 45    |
|    time_elapsed         | 1488  |
|    total_timesteps      | 184320 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.232 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 5007.260 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.5  |
|    ep_rew_mean          | 187.555 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 46    |
|    time_elapsed         | 1521  |
|    total_timesteps      | 188416 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.288 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4182.579 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.8  |
|    ep_rew_mean          | 173.842 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.4 |
|    iteration            | 47    |
|    time_elapsed         | 1554  |
|    total_timesteps      | 192512 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    entropy_loss         | 0.341 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4649.531 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.2  |
|    ep_rew_mean          | 268.735 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 48    |
|    time_elapsed         | 1587  |
|    total_timesteps      | 196608 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.277 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4737.683 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 73.5  |
|    ep_rew_mean          | 287.813 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.0 |
|    iteration            | 49    |
|    time_elapsed         | 1621  |
|    total_timesteps      | 200704 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.278 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 5974.337 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.9  |
|    ep_rew_mean          | 176.154 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.0 |
|    iteration            | 50    |
|    time_elapsed         | 1654  |
|    total_timesteps      | 204800 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.253 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4848.377 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.0  |
|    ep_rew_mean          | 203.062 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.3 |
|    iteration            | 51    |
|    time_elapsed         | 1688  |
|    total_timesteps      | 208896 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.188 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 5133.218 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.5  |
|    ep_rew_mean          | 231.440 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 52    |
|    time_elapsed         | 1721  |
|    total_timesteps      | 212992 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.204 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4944.062 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.6  |
|    ep_rew_mean          | 270.401 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 53    |
|    time_elapsed         | 1755  |
|    total_timesteps      | 217088 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.235 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5314.142 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.7  |
|    ep_rew_mean          | 174.831 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.4 |
|    iteration            | 54    |
|    time_elapsed         | 1788  |
|    total_timesteps      | 221184 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.222 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4677.985 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.5  |
|    ep_rew_mean          | 165.823 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.7 |
|    iteration            | 55    |
|    time_elapsed         | 1822  |
|    total_timesteps      | 225280 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.249 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4363.921 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.8  |
|    ep_rew_mean          | 288.964 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.9 |
|    iteration            | 56    |
|    time_elapsed         | 1854  |
|    total_timesteps      | 229376 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.260 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5295.964 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.5  |
|    ep_rew_mean          | 173.916 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.8 |
|    iteration            | 57    |
|    time_elapsed         | 1887  |
|    total_timesteps      | 233472 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.272 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4994.020 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.9  |
|    ep_rew_mean          | 265.446 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.4 |
|    iteration            | 58    |
|    time_elapsed         | 1919  |
|    total_timesteps      | 237568 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.243 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4465.240 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.3  |
|    ep_rew_mean          | 199.717 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.8 |
|    iteration            | 59    |
|    time_elapsed         | 1952  |
|    total_timesteps      | 241664 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.189 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4710.286 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.4  |
|    ep_rew_mean          | 193.836 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.4 |
|    iteration            | 60    |
|    time_elapsed         | 1985  |
|    total_timesteps      | 245760 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.195 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4601.068 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 49.5  |
|    ep_rew_mean          | 88.439 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.9 |
|    iteration            | 61    |
|    time_elapsed         | 2016  |
|    total_timesteps      | 249856 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.234 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4173.989 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.0  |
|    ep_rew_mean          | 136.195 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 139.1 |
|    iteration            | 62    |
|    time_elapsed         | 2048  |
|    total_timesteps      | 253952 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.199 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5016.986 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.7  |
|    ep_rew_mean          | 243.173 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.4 |
|    iteration            | 63    |
|    time_elapsed         | 2081  |
|    total_timesteps      | 258048 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    entropy_loss         | 0.197 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5269.318 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.5  |
|    ep_rew_mean          | 163.650 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 136.1 |
|    iteration            | 64    |
|    time_elapsed         | 2113  |
|    total_timesteps      | 262144 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.188 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 5290.386 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.1  |
|    ep_rew_mean          | 154.332 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.5 |
|    iteration            | 65    |
|    time_elapsed         | 2146  |
|    total_timesteps      | 266240 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    entropy_loss         | 0.170 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5007.730 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.9  |
|    ep_rew_mean          | 229.714 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.2 |
|    iteration            | 66    |
|    time_elapsed         | 2179  |
|    total_timesteps      | 270336 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.177 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4987.198 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.6  |
|    ep_rew_mean          | 189.830 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.9 |
|    iteration            | 67    |
|    time_elapsed         | 2212  |
|    total_timesteps      | 274432 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.176 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4967.358 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.4  |
|    ep_rew_mean          | 237.952 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 68    |
|    time_elapsed         | 2246  |
|    total_timesteps      | 278528 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.217 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5289.287 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.1  |
|    ep_rew_mean          | 212.791 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 69    |
|    time_elapsed         | 2279  |
|    total_timesteps      | 282624 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.210 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4890.985 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.8  |
|    ep_rew_mean          | 184.780 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.4 |
|    iteration            | 70    |
|    time_elapsed         | 2311  |
|    total_timesteps      | 286720 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.179 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4663.822 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.9  |
|    ep_rew_mean          | 217.569 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.0 |
|    iteration            | 71    |
|    time_elapsed         | 2344  |
|    total_timesteps      | 290816 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    entropy_loss         | 0.128 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4261.919 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.1  |
|    ep_rew_mean          | 284.086 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 137.8 |
|    iteration            | 72    |
|    time_elapsed         | 2376  |
|    total_timesteps      | 294912 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    entropy_loss         | 0.111 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4898.619 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.4  |
|    ep_rew_mean          | 228.904 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.1 |
|    iteration            | 73    |
|    time_elapsed         | 2409  |
|    total_timesteps      | 299008 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.106 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5274.357 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.2  |
|    ep_rew_mean          | 261.696 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 138.1 |
|    iteration            | 74    |
|    time_elapsed         | 2441  |
|    total_timesteps      | 303104 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.000 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.104 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5695.942 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.1  |
|    ep_rew_mean          | 246.724 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 136.5 |
|    iteration            | 75    |
|    time_elapsed         | 2473  |
|    total_timesteps      | 307200 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.100 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5313.099 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.7  |
|    ep_rew_mean          | 141.616 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.5 |
|    iteration            | 76    |
|    time_elapsed         | 2506  |
|    total_timesteps      | 311296 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.009 |
|    entropy_loss         | 0.133 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5528.190 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.3  |
|    ep_rew_mean          | 157.321 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 77    |
|    time_elapsed         | 2539  |
|    total_timesteps      | 315392 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.325 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4157.858 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 75.9  |
|    ep_rew_mean          | 226.276 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 78    |
|    time_elapsed         | 2573  |
|    total_timesteps      | 319488 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.060 |
|    entropy_loss         | 0.589 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3433.392 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.5  |
|    ep_rew_mean          | 164.574 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 79    |
|    time_elapsed         | 2606  |
|    total_timesteps      | 323584 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.043 |
|    entropy_loss         | 0.573 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 3525.963 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.3  |
|    ep_rew_mean          | 139.252 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 80    |
|    time_elapsed         | 2639  |
|    total_timesteps      | 327680 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.037 |
|    entropy_loss         | 0.534 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3430.164 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.8  |
|    ep_rew_mean          | 209.615 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 81    |
|    time_elapsed         | 2672  |
|    total_timesteps      | 331776 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.562 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3188.678 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.4  |
|    ep_rew_mean          | 200.478 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 82    |
|    time_elapsed         | 2705  |
|    total_timesteps      | 335872 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.575 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4080.800 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.3  |
|    ep_rew_mean          | 158.695 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 83    |
|    time_elapsed         | 2739  |
|    total_timesteps      | 339968 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.032 |
|    entropy_loss         | 0.484 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3940.845 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.2  |
|    ep_rew_mean          | 185.525 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 84    |
|    time_elapsed         | 2772  |
|    total_timesteps      | 344064 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    entropy_loss         | 0.504 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3782.334 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.1  |
|    ep_rew_mean          | 86.138 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 85    |
|    time_elapsed         | 2805  |
|    total_timesteps      | 348160 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.036 |
|    entropy_loss         | 0.523 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3553.201 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.4  |
|    ep_rew_mean          | 190.467 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 86    |
|    time_elapsed         | 2838  |
|    total_timesteps      | 352256 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.446 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3633.683 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.5  |
|    ep_rew_mean          | 121.254 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 87    |
|    time_elapsed         | 2871  |
|    total_timesteps      | 356352 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.034 |
|    entropy_loss         | 0.485 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3540.665 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.7  |
|    ep_rew_mean          | 196.508 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 88    |
|    time_elapsed         | 2905  |
|    total_timesteps      | 360448 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.458 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3681.493 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.5  |
|    ep_rew_mean          | 163.146 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 89    |
|    time_elapsed         | 2938  |
|    total_timesteps      | 364544 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.031 |
|    entropy_loss         | 0.533 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3843.165 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 50.5  |
|    ep_rew_mean          | 117.193 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 90    |
|    time_elapsed         | 2971  |
|    total_timesteps      | 368640 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.485 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4317.721 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.6  |
|    ep_rew_mean          | 152.889 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 91    |
|    time_elapsed         | 3004  |
|    total_timesteps      | 372736 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.408 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3764.680 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.6  |
|    ep_rew_mean          | 170.725 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 92    |
|    time_elapsed         | 3037  |
|    total_timesteps      | 376832 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.328 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4736.669 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.4  |
|    ep_rew_mean          | 128.912 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 93    |
|    time_elapsed         | 3071  |
|    total_timesteps      | 380928 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.285 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4364.536 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.8  |
|    ep_rew_mean          | 263.823 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 94    |
|    time_elapsed         | 3104  |
|    total_timesteps      | 385024 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.351 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4762.895 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.8  |
|    ep_rew_mean          | 217.575 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 95    |
|    time_elapsed         | 3137  |
|    total_timesteps      | 389120 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    entropy_loss         | 0.361 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.002 |
|    value_loss           | 4479.645 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 71.3  |
|    ep_rew_mean          | 238.278 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 96    |
|    time_elapsed         | 3170  |
|    total_timesteps      | 393216 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.321 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5044.648 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.5  |
|    ep_rew_mean          | 124.206 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 97    |
|    time_elapsed         | 3203  |
|    total_timesteps      | 397312 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.329 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4272.298 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.9  |
|    ep_rew_mean          | 143.786 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.0 |
|    iteration            | 98    |
|    time_elapsed         | 3236  |
|    total_timesteps      | 401408 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.271 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4473.822 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 56.2  |
|    ep_rew_mean          | 154.117 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 99    |
|    time_elapsed         | 3270  |
|    total_timesteps      | 405504 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.284 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3896.827 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.6  |
|    ep_rew_mean          | 217.677 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 100   |
|    time_elapsed         | 3303  |
|    total_timesteps      | 409600 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.259 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3831.572 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.0  |
|    ep_rew_mean          | 206.919 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 101   |
|    time_elapsed         | 3336  |
|    total_timesteps      | 413696 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.362 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4174.915 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.6  |
|    ep_rew_mean          | 220.806 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 102   |
|    time_elapsed         | 3369  |
|    total_timesteps      | 417792 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.393 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4290.308 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 50.1  |
|    ep_rew_mean          | 91.719 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 103   |
|    time_elapsed         | 3402  |
|    total_timesteps      | 421888 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.353 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4107.622 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.7  |
|    ep_rew_mean          | 155.501 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 104   |
|    time_elapsed         | 3436  |
|    total_timesteps      | 425984 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.370 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3599.475 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.8  |
|    ep_rew_mean          | 118.979 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 105   |
|    time_elapsed         | 3469  |
|    total_timesteps      | 430080 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.310 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4362.945 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.5  |
|    ep_rew_mean          | 254.644 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 106   |
|    time_elapsed         | 3502  |
|    total_timesteps      | 434176 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.297 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5287.920 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.1  |
|    ep_rew_mean          | 160.425 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 107   |
|    time_elapsed         | 3535  |
|    total_timesteps      | 438272 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.305 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4800.305 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.0  |
|    ep_rew_mean          | 131.228 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 108   |
|    time_elapsed         | 3568  |
|    total_timesteps      | 442368 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.264 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4389.488 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.1  |
|    ep_rew_mean          | 128.308 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 109   |
|    time_elapsed         | 3601  |
|    total_timesteps      | 446464 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.324 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4229.764 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.8  |
|    ep_rew_mean          | 150.231 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.7 |
|    iteration            | 110   |
|    time_elapsed         | 3635  |
|    total_timesteps      | 450560 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.298 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4533.574 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.7  |
|    ep_rew_mean          | 216.893 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 111   |
|    time_elapsed         | 3668  |
|    total_timesteps      | 454656 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.308 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4554.881 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.3  |
|    ep_rew_mean          | 220.836 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 112   |
|    time_elapsed         | 3701  |
|    total_timesteps      | 458752 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.333 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4669.185 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.3  |
|    ep_rew_mean          | 179.253 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 113   |
|    time_elapsed         | 3734  |
|    total_timesteps      | 462848 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.295 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4186.087 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.8  |
|    ep_rew_mean          | 173.952 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 114   |
|    time_elapsed         | 3767  |
|    total_timesteps      | 466944 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.277 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3913.463 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.6  |
|    ep_rew_mean          | 141.753 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 115   |
|    time_elapsed         | 3800  |
|    total_timesteps      | 471040 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.291 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3908.347 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.2  |
|    ep_rew_mean          | 220.023 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 116   |
|    time_elapsed         | 3834  |
|    total_timesteps      | 475136 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.306 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4391.417 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.0  |
|    ep_rew_mean          | 164.063 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 117   |
|    time_elapsed         | 3867  |
|    total_timesteps      | 479232 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.313 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4399.527 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.4  |
|    ep_rew_mean          | 229.254 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.0 |
|    iteration            | 118   |
|    time_elapsed         | 3900  |
|    total_timesteps      | 483328 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.305 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4566.119 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 76.4  |
|    ep_rew_mean          | 305.577 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 119   |
|    time_elapsed         | 3933  |
|    total_timesteps      | 487424 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.322 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4767.483 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.1  |
|    ep_rew_mean          | 203.619 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 120   |
|    time_elapsed         | 3967  |
|    total_timesteps      | 491520 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.275 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4987.969 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.9  |
|    ep_rew_mean          | 187.886 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 121   |
|    time_elapsed         | 4000  |
|    total_timesteps      | 495616 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.253 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4578.964 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.2  |
|    ep_rew_mean          | 208.850 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 122   |
|    time_elapsed         | 4033  |
|    total_timesteps      | 499712 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.300 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4497.395 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.4  |
|    ep_rew_mean          | 228.004 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 123   |
|    time_elapsed         | 4066  |
|    total_timesteps      | 503808 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.253 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4876.553 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 50.5  |
|    ep_rew_mean          | 96.110 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 124   |
|    time_elapsed         | 4099  |
|    total_timesteps      | 507904 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.263 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4602.410 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.7  |
|    ep_rew_mean          | 149.779 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 125   |
|    time_elapsed         | 4132  |
|    total_timesteps      | 512000 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.306 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4295.370 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.9  |
|    ep_rew_mean          | 197.700 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 126   |
|    time_elapsed         | 4166  |
|    total_timesteps      | 516096 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.343 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4489.908 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.2  |
|    ep_rew_mean          | 150.026 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 127   |
|    time_elapsed         | 4199  |
|    total_timesteps      | 520192 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.320 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4073.750 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.5  |
|    ep_rew_mean          | 160.817 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 128   |
|    time_elapsed         | 4232  |
|    total_timesteps      | 524288 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    entropy_loss         | 0.283 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4213.105 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.4  |
|    ep_rew_mean          | 170.969 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 129   |
|    time_elapsed         | 4265  |
|    total_timesteps      | 528384 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.309 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4255.251 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.5  |
|    ep_rew_mean          | 210.332 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.8 |
|    iteration            | 130   |
|    time_elapsed         | 4298  |
|    total_timesteps      | 532480 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.326 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4386.672 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.4  |
|    ep_rew_mean          | 169.366 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.1 |
|    iteration            | 131   |
|    time_elapsed         | 4331  |
|    total_timesteps      | 536576 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.377 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3835.627 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.6  |
|    ep_rew_mean          | 231.213 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 132   |
|    time_elapsed         | 4365  |
|    total_timesteps      | 540672 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.332 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4309.553 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.2  |
|    ep_rew_mean          | 169.984 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 133.9 |
|    iteration            | 133   |
|    time_elapsed         | 4398  |
|    total_timesteps      | 544768 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.343 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4626.551 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.8  |
|    ep_rew_mean          | 176.736 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.3 |
|    iteration            | 134   |
|    time_elapsed         | 4431  |
|    total_timesteps      | 548864 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.309 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4616.315 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.8  |
|    ep_rew_mean          | 172.408 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.4 |
|    iteration            | 135   |
|    time_elapsed         | 4464  |
|    total_timesteps      | 552960 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.013 |
|    clip_fraction        | 0.045 |
|    entropy_loss         | 0.376 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.005 |
|    value_loss           | 4649.920 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 85.9  |
|    ep_rew_mean          | 256.896 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.2 |
|    iteration            | 136   |
|    time_elapsed         | 4497  |
|    total_timesteps      | 557056 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.065 |
|    entropy_loss         | 0.514 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3084.542 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 56.7  |
|    ep_rew_mean          | 87.515 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 137   |
|    time_elapsed         | 4530  |
|    total_timesteps      | 561152 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.039 |
|    entropy_loss         | 0.446 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 2746.719 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.5  |
|    ep_rew_mean          | 197.626 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 138   |
|    time_elapsed         | 4563  |
|    total_timesteps      | 565248 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.041 |
|    entropy_loss         | 0.439 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3480.002 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.7  |
|    ep_rew_mean          | 142.891 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 139   |
|    time_elapsed         | 4596  |
|    total_timesteps      | 569344 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.459 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3393.366 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.9  |
|    ep_rew_mean          | 197.842 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.8 |
|    iteration            | 140   |
|    time_elapsed         | 4629  |
|    total_timesteps      | 573440 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.042 |
|    entropy_loss         | 0.459 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3241.963 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.4  |
|    ep_rew_mean          | 159.950 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.5 |
|    iteration            | 141   |
|    time_elapsed         | 4662  |
|    total_timesteps      | 577536 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.036 |
|    entropy_loss         | 0.384 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 3762.723 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.0  |
|    ep_rew_mean          | 136.510 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 142   |
|    time_elapsed         | 4695  |
|    total_timesteps      | 581632 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.371 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3131.136 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.1  |
|    ep_rew_mean          | 127.186 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 143   |
|    time_elapsed         | 4728  |
|    total_timesteps      | 585728 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    entropy_loss         | 0.333 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3975.684 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.5  |
|    ep_rew_mean          | 139.049 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 144   |
|    time_elapsed         | 4761  |
|    total_timesteps      | 589824 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.028 |
|    entropy_loss         | 0.316 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3971.656 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.5  |
|    ep_rew_mean          | 119.585 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 145   |
|    time_elapsed         | 4794  |
|    total_timesteps      | 593920 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.267 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3889.099 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.1  |
|    ep_rew_mean          | 94.475 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 146   |
|    time_elapsed         | 4827  |
|    total_timesteps      | 598016 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.345 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3874.047 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.0  |
|    ep_rew_mean          | 169.114 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.8 |
|    iteration            | 147   |
|    time_elapsed         | 4860  |
|    total_timesteps      | 602112 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.035 |
|    entropy_loss         | 0.444 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3874.855 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.6  |
|    ep_rew_mean          | 99.745 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 148   |
|    time_elapsed         | 4893  |
|    total_timesteps      | 606208 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.402 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3619.576 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 75.2  |
|    ep_rew_mean          | 232.394 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 149   |
|    time_elapsed         | 4925  |
|    total_timesteps      | 610304 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.038 |
|    entropy_loss         | 0.493 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3412.905 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.2  |
|    ep_rew_mean          | 157.539 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 150   |
|    time_elapsed         | 4958  |
|    total_timesteps      | 614400 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.035 |
|    entropy_loss         | 0.545 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3562.206 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.0  |
|    ep_rew_mean          | 157.852 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 151   |
|    time_elapsed         | 4991  |
|    total_timesteps      | 618496 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.032 |
|    entropy_loss         | 0.490 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3512.971 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.7  |
|    ep_rew_mean          | 121.243 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.8 |
|    iteration            | 152   |
|    time_elapsed         | 5024  |
|    total_timesteps      | 622592 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.036 |
|    entropy_loss         | 0.604 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3305.438 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.2  |
|    ep_rew_mean          | 153.426 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 153   |
|    time_elapsed         | 5057  |
|    total_timesteps      | 626688 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.080 |
|    entropy_loss         | 0.795 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 2775.165 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.8  |
|    ep_rew_mean          | 53.202 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.9 |
|    iteration            | 154   |
|    time_elapsed         | 5090  |
|    total_timesteps      | 630784 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.091 |
|    entropy_loss         | 0.902 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 2314.589 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.0  |
|    ep_rew_mean          | 119.482 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 155   |
|    time_elapsed         | 5123  |
|    total_timesteps      | 634880 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.044 |
|    entropy_loss         | 0.821 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 2903.096 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.3  |
|    ep_rew_mean          | 114.244 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 156   |
|    time_elapsed         | 5156  |
|    total_timesteps      | 638976 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.039 |
|    entropy_loss         | 0.741 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3000.315 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.3  |
|    ep_rew_mean          | 149.999 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 157   |
|    time_elapsed         | 5189  |
|    total_timesteps      | 643072 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.660 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3298.957 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.4  |
|    ep_rew_mean          | 212.270 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 158   |
|    time_elapsed         | 5222  |
|    total_timesteps      | 647168 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.630 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3781.174 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.1  |
|    ep_rew_mean          | 215.270 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 159   |
|    time_elapsed         | 5255  |
|    total_timesteps      | 651264 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.038 |
|    entropy_loss         | 0.503 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.005 |
|    value_loss           | 3825.589 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.4  |
|    ep_rew_mean          | 188.595 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 160   |
|    time_elapsed         | 5288  |
|    total_timesteps      | 655360 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.032 |
|    entropy_loss         | 0.460 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3892.451 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.9  |
|    ep_rew_mean          | 203.849 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 161   |
|    time_elapsed         | 5320  |
|    total_timesteps      | 659456 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.423 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3640.512 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.4  |
|    ep_rew_mean          | 150.869 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 162   |
|    time_elapsed         | 5353  |
|    total_timesteps      | 663552 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.396 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4196.387 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.5  |
|    ep_rew_mean          | 175.890 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 163   |
|    time_elapsed         | 5386  |
|    total_timesteps      | 667648 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.402 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3916.857 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 50.6  |
|    ep_rew_mean          | 98.792 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 164   |
|    time_elapsed         | 5419  |
|    total_timesteps      | 671744 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    entropy_loss         | 0.432 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3759.369 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.0  |
|    ep_rew_mean          | 237.074 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 165   |
|    time_elapsed         | 5452  |
|    total_timesteps      | 675840 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.457 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4231.701 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 71.4  |
|    ep_rew_mean          | 209.506 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 166   |
|    time_elapsed         | 5485  |
|    total_timesteps      | 679936 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.033 |
|    entropy_loss         | 0.596 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.002 |
|    value_loss           | 3834.304 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.4  |
|    ep_rew_mean          | 95.563 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 167   |
|    time_elapsed         | 5518  |
|    total_timesteps      | 684032 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.025 |
|    entropy_loss         | 0.497 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3566.267 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 73.8  |
|    ep_rew_mean          | 220.051 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 168   |
|    time_elapsed         | 5551  |
|    total_timesteps      | 688128 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.026 |
|    entropy_loss         | 0.459 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 3532.821 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.7  |
|    ep_rew_mean          | 154.174 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 169   |
|    time_elapsed         | 5584  |
|    total_timesteps      | 692224 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.425 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3587.265 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.7  |
|    ep_rew_mean          | 218.257 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 170   |
|    time_elapsed         | 5617  |
|    total_timesteps      | 696320 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.350 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4202.262 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.4  |
|    ep_rew_mean          | 188.636 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 171   |
|    time_elapsed         | 5650  |
|    total_timesteps      | 700416 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.027 |
|    entropy_loss         | 0.371 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4464.080 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.5  |
|    ep_rew_mean          | 132.171 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 172   |
|    time_elapsed         | 5683  |
|    total_timesteps      | 704512 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.361 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4020.021 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.6  |
|    ep_rew_mean          | 129.320 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 173   |
|    time_elapsed         | 5716  |
|    total_timesteps      | 708608 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.030 |
|    entropy_loss         | 0.393 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3656.340 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 49.3  |
|    ep_rew_mean          | 102.473 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 174   |
|    time_elapsed         | 5748  |
|    total_timesteps      | 712704 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.304 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3910.119 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.0  |
|    ep_rew_mean          | 139.022 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 175   |
|    time_elapsed         | 5781  |
|    total_timesteps      | 716800 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.300 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4420.372 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.5  |
|    ep_rew_mean          | 172.879 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 176   |
|    time_elapsed         | 5814  |
|    total_timesteps      | 720896 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.244 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 4597.758 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.7  |
|    ep_rew_mean          | 232.463 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 177   |
|    time_elapsed         | 5847  |
|    total_timesteps      | 724992 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.226 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5257.391 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.1  |
|    ep_rew_mean          | 251.117 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 178   |
|    time_elapsed         | 5880  |
|    total_timesteps      | 729088 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.280 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4941.261 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.3  |
|    ep_rew_mean          | 207.256 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 179   |
|    time_elapsed         | 5913  |
|    total_timesteps      | 733184 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.303 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4514.661 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 66.2  |
|    ep_rew_mean          | 235.423 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 180   |
|    time_elapsed         | 5946  |
|    total_timesteps      | 737280 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.282 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4221.131 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 49.3  |
|    ep_rew_mean          | 95.188 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 181   |
|    time_elapsed         | 5979  |
|    total_timesteps      | 741376 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.245 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4587.466 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.5  |
|    ep_rew_mean          | 203.167 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 182   |
|    time_elapsed         | 6012  |
|    total_timesteps      | 745472 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.283 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4434.550 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.5  |
|    ep_rew_mean          | 196.873 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 183   |
|    time_elapsed         | 6045  |
|    total_timesteps      | 749568 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.222 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5015.358 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.5  |
|    ep_rew_mean          | 204.235 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 184   |
|    time_elapsed         | 6078  |
|    total_timesteps      | 753664 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    entropy_loss         | 0.211 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5124.468 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.2  |
|    ep_rew_mean          | 235.569 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 185   |
|    time_elapsed         | 6111  |
|    total_timesteps      | 757760 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.009 |
|    entropy_loss         | 0.164 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5136.441 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 75.1  |
|    ep_rew_mean          | 296.482 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 186   |
|    time_elapsed         | 6144  |
|    total_timesteps      | 761856 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.189 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5286.875 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.1  |
|    ep_rew_mean          | 221.286 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 187   |
|    time_elapsed         | 6176  |
|    total_timesteps      | 765952 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.010 |
|    entropy_loss         | 0.146 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5070.769 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.8  |
|    ep_rew_mean          | 240.967 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 188   |
|    time_elapsed         | 6209  |
|    total_timesteps      | 770048 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.008 |
|    entropy_loss         | 0.112 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5018.341 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.6  |
|    ep_rew_mean          | 254.847 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 189   |
|    time_elapsed         | 6242  |
|    total_timesteps      | 774144 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.110 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5088.090 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.7  |
|    ep_rew_mean          | 169.807 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 190   |
|    time_elapsed         | 6275  |
|    total_timesteps      | 778240 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.000 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.084 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5036.734 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.5  |
|    ep_rew_mean          | 166.244 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 191   |
|    time_elapsed         | 6308  |
|    total_timesteps      | 782336 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.000 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.106 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 5169.072 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.5  |
|    ep_rew_mean          | 194.132 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 192   |
|    time_elapsed         | 6341  |
|    total_timesteps      | 786432 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.013 |
|    entropy_loss         | 0.122 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5002.660 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.3  |
|    ep_rew_mean          | 222.382 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 193   |
|    time_elapsed         | 6374  |
|    total_timesteps      | 790528 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.000 |
|    clip_fraction        | 0.005 |
|    entropy_loss         | 0.078 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5361.351 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 64.0  |
|    ep_rew_mean          | 223.592 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 194   |
|    time_elapsed         | 6407  |
|    total_timesteps      | 794624 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.007 |
|    entropy_loss         | 0.099 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5256.008 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.5  |
|    ep_rew_mean          | 212.084 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 195   |
|    time_elapsed         | 6440  |
|    total_timesteps      | 798720 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.000 |
|    clip_fraction        | 0.006 |
|    entropy_loss         | 0.070 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 5285.057 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.5  |
|    ep_rew_mean          | 223.129 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 196   |
|    time_elapsed         | 6473  |
|    total_timesteps      | 802816 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.011 |
|    clip_fraction        | 0.055 |
|    entropy_loss         | 0.211 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.007 |
|    value_loss           | 4796.258 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.6  |
|    ep_rew_mean          | 144.418 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 197   |
|    time_elapsed         | 6505  |
|    total_timesteps      | 806912 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.082 |
|    clip_fraction        | 0.207 |
|    entropy_loss         | 0.675 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.024 |
|    value_loss           | 3201.166 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 63.7  |
|    ep_rew_mean          | 143.710 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 198   |
|    time_elapsed         | 6538  |
|    total_timesteps      | 811008 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.006 |
|    clip_fraction        | 0.067 |
|    entropy_loss         | 0.708 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 2893.893 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 67.0  |
|    ep_rew_mean          | 139.513 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 199   |
|    time_elapsed         | 6571  |
|    total_timesteps      | 815104 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.032 |
|    entropy_loss         | 0.642 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 2930.674 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.3  |
|    ep_rew_mean          | 162.082 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.9 |
|    iteration            | 200   |
|    time_elapsed         | 6604  |
|    total_timesteps      | 819200 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.623 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3346.184 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.6  |
|    ep_rew_mean          | 91.005 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 201   |
|    time_elapsed         | 6637  |
|    total_timesteps      | 823296 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.004 |
|    clip_fraction        | 0.034 |
|    entropy_loss         | 0.642 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 3194.114 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 74.6  |
|    ep_rew_mean          | 181.967 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 202   |
|    time_elapsed         | 6670  |
|    total_timesteps      | 827392 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.041 |
|    entropy_loss         | 0.574 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.003 |
|    value_loss           | 3621.915 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.1  |
|    ep_rew_mean          | 90.285 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 203   |
|    time_elapsed         | 6703  |
|    total_timesteps      | 831488 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.474 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3563.960 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.4  |
|    ep_rew_mean          | 162.922 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 204   |
|    time_elapsed         | 6736  |
|    total_timesteps      | 835584 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.445 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4003.034 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.4  |
|    ep_rew_mean          | 142.061 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 205   |
|    time_elapsed         | 6769  |
|    total_timesteps      | 839680 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.011 |
|    entropy_loss         | 0.384 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4138.411 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.0  |
|    ep_rew_mean          | 240.495 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 206   |
|    time_elapsed         | 6802  |
|    total_timesteps      | 843776 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.372 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3689.820 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.8  |
|    ep_rew_mean          | 132.744 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 207   |
|    time_elapsed         | 6835  |
|    total_timesteps      | 847872 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.331 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3732.206 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.8  |
|    ep_rew_mean          | 256.988 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 208   |
|    time_elapsed         | 6868  |
|    total_timesteps      | 851968 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.358 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.002 |
|    value_loss           | 4747.596 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.0  |
|    ep_rew_mean          | 155.732 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 209   |
|    time_elapsed         | 6900  |
|    total_timesteps      | 856064 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.357 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4257.734 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.1  |
|    ep_rew_mean          | 149.740 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 210   |
|    time_elapsed         | 6933  |
|    total_timesteps      | 860160 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.319 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4316.145 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 71.4  |
|    ep_rew_mean          | 260.559 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 211   |
|    time_elapsed         | 6966  |
|    total_timesteps      | 864256 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.024 |
|    entropy_loss         | 0.367 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 3915.085 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.4  |
|    ep_rew_mean          | 177.030 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 212   |
|    time_elapsed         | 6999  |
|    total_timesteps      | 868352 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.332 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4894.992 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.8  |
|    ep_rew_mean          | 114.184 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 213   |
|    time_elapsed         | 7032  |
|    total_timesteps      | 872448 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.296 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3968.666 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 52.8  |
|    ep_rew_mean          | 138.236 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 214   |
|    time_elapsed         | 7065  |
|    total_timesteps      | 876544 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.260 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4607.970 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 61.1  |
|    ep_rew_mean          | 192.004 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 215   |
|    time_elapsed         | 7098  |
|    total_timesteps      | 880640 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.280 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4431.944 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.8  |
|    ep_rew_mean          | 280.929 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 216   |
|    time_elapsed         | 7131  |
|    total_timesteps      | 884736 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.014 |
|    entropy_loss         | 0.290 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4674.298 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 69.7  |
|    ep_rew_mean          | 238.652 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 217   |
|    time_elapsed         | 7164  |
|    total_timesteps      | 888832 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.337 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4756.689 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.8  |
|    ep_rew_mean          | 154.004 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 218   |
|    time_elapsed         | 7197  |
|    total_timesteps      | 892928 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.344 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 3920.061 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.8  |
|    ep_rew_mean          | 132.110 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 219   |
|    time_elapsed         | 7230  |
|    total_timesteps      | 897024 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.005 |
|    clip_fraction        | 0.034 |
|    entropy_loss         | 0.416 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3744.742 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 68.6  |
|    ep_rew_mean          | 234.425 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 220   |
|    time_elapsed         | 7263  |
|    total_timesteps      | 901120 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.361 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3798.345 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.5  |
|    ep_rew_mean          | 188.563 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 221   |
|    time_elapsed         | 7295  |
|    total_timesteps      | 905216 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.359 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4440.086 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 71.4  |
|    ep_rew_mean          | 254.624 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 222   |
|    time_elapsed         | 7328  |
|    total_timesteps      | 909312 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.335 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4460.173 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 59.8  |
|    ep_rew_mean          | 185.358 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 223   |
|    time_elapsed         | 7361  |
|    total_timesteps      | 913408 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.015 |
|    entropy_loss         | 0.302 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4306.490 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.6  |
|    ep_rew_mean          | 165.414 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 224   |
|    time_elapsed         | 7394  |
|    total_timesteps      | 917504 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.026 |
|    entropy_loss         | 0.343 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.002 |
|    value_loss           | 3724.608 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 75.2  |
|    ep_rew_mean          | 252.318 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 225   |
|    time_elapsed         | 7427  |
|    total_timesteps      | 921600 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.379 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4161.848 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 76.5  |
|    ep_rew_mean          | 299.349 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 226   |
|    time_elapsed         | 7460  |
|    total_timesteps      | 925696 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.402 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4469.726 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 72.6  |
|    ep_rew_mean          | 288.572 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 227   |
|    time_elapsed         | 7493  |
|    total_timesteps      | 929792 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.404 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4240.848 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 54.3  |
|    ep_rew_mean          | 119.964 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 228   |
|    time_elapsed         | 7526  |
|    total_timesteps      | 933888 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.339 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4056.633 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 56.1  |
|    ep_rew_mean          | 139.874 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 229   |
|    time_elapsed         | 7559  |
|    total_timesteps      | 937984 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.017 |
|    entropy_loss         | 0.352 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4370.843 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 65.0  |
|    ep_rew_mean          | 211.098 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 230   |
|    time_elapsed         | 7592  |
|    total_timesteps      | 942080 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.343 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4277.093 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.3  |
|    ep_rew_mean          | 160.480 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 231   |
|    time_elapsed         | 7625  |
|    total_timesteps      | 946176 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.347 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4656.031 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 53.3  |
|    ep_rew_mean          | 116.048 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 232   |
|    time_elapsed         | 7658  |
|    total_timesteps      | 950272 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.036 |
|    entropy_loss         | 0.379 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 3725.445 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.4  |
|    ep_rew_mean          | 269.324 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.9 |
|    iteration            | 233   |
|    time_elapsed         | 7690  |
|    total_timesteps      | 954368 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.360 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 3867.417 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 55.1  |
|    ep_rew_mean          | 127.058 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 234   |
|    time_elapsed         | 7723  |
|    total_timesteps      | 958464 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.018 |
|    entropy_loss         | 0.331 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4300.388 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.3  |
|    ep_rew_mean          | 151.098 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 235   |
|    time_elapsed         | 7756  |
|    total_timesteps      | 962560 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.316 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4290.731 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.2  |
|    ep_rew_mean          | 167.735 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 236   |
|    time_elapsed         | 7789  |
|    total_timesteps      | 966656 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.019 |
|    entropy_loss         | 0.280 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4441.617 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.5  |
|    ep_rew_mean          | 168.170 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 237   |
|    time_elapsed         | 7822  |
|    total_timesteps      | 970752 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.012 |
|    entropy_loss         | 0.231 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4056.642 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.6  |
|    ep_rew_mean          | 192.220 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.6 |
|    iteration            | 238   |
|    time_elapsed         | 7855  |
|    total_timesteps      | 974848 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.265 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.002 |
|    value_loss           | 4512.587 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 60.4  |
|    ep_rew_mean          | 188.047 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.1 |
|    iteration            | 239   |
|    time_elapsed         | 7888  |
|    total_timesteps      | 978944 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.021 |
|    entropy_loss         | 0.284 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4664.615 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 62.0  |
|    ep_rew_mean          | 198.625 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 240   |
|    time_elapsed         | 7921  |
|    total_timesteps      | 983040 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.016 |
|    entropy_loss         | 0.273 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4313.383 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 70.5  |
|    ep_rew_mean          | 265.963 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 241   |
|    time_elapsed         | 7954  |
|    total_timesteps      | 987136 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.001 |
|    clip_fraction        | 0.022 |
|    entropy_loss         | 0.291 |
|    explained_variance   | -0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.001 |
|    value_loss           | 4910.381 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 56.0  |
|    ep_rew_mean          | 146.967 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 242   |
|    time_elapsed         | 7987  |
|    total_timesteps      | 991232 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.020 |
|    entropy_loss         | 0.307 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | -0.000 |
|    value_loss           | 4617.485 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.1  |
|    ep_rew_mean          | 145.689 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 134.7 |
|    iteration            | 243   |
|    time_elapsed         | 8020  |
|    total_timesteps      | 995328 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.029 |
|    entropy_loss         | 0.408 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.000 |
|    value_loss           | 4634.071 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 58.5  |
|    ep_rew_mean          | 159.419 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 244   |
|    time_elapsed         | 8053  |
|    total_timesteps      | 999424 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.003 |
|    clip_fraction        | 0.026 |
|    entropy_loss         | 0.322 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4178.277 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
---------------------------------
| rollout/                |       |
|    ep_len_mean          | 57.6  |
|    ep_rew_mean          | 137.439 |
|    best_mean_reward     | 349.046 |
|-------------------------|-------|
| time/                   |       |
|    fps                  | 135.0 |
|    iteration            | 245   |
|    time_elapsed         | 8086  |
|    total_timesteps      | 1003520 |
|-------------------------|-------|
| train/                  |       |
|    approx_kl            | 0.002 |
|    clip_fraction        | 0.023 |
|    entropy_loss         | 0.347 |
|    explained_variance   | 0.000 |
|    learning_rate        | 0.00025 |
|    policy_loss          | 0.001 |
|    value_loss           | 4000.912 |
|    rnd_loss             | 0.000 |
|    reward_weight        | 0.250 |
---------------------------------
Training completed!
============================== Final Statistics ==============================
Total episodes: 15711
Average episode reward: 169.047
Average episode length: 63.3
Best mean reward: 349.046
Total timesteps: 1003520
Total training time: 8088.6s
Best model saved to: models/VizdoomCorridor_ppo_infini_rnd_vit_best.pt
